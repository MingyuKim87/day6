{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgyukim/.conda/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_train.json -O KorQuAD_v1.0_train.json\n",
    "#!wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_dev.json -O KorQuAD_v1.0_dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def korquad_to_dataframe(data):\n",
    "    rows = []\n",
    "    for paragraph in data[\"data\"]:\n",
    "        paragraph_title = paragraph[\"title\"]\n",
    "\n",
    "        for qa in paragraph[\"paragraphs\"]:\n",
    "            context = qa[\"context\"]\n",
    "\n",
    "            for question in qa[\"qas\"]:\n",
    "                q = question[\"question\"]\n",
    "                qa_id = question[\"id\"]\n",
    "\n",
    "                for answer in question[\"answers\"]:\n",
    "                    a = answer[\"text\"]\n",
    "                    rows.append({\n",
    "                        'question' : q,\n",
    "                        'answer' : a,\n",
    "                        'qa_id' : qa_id,\n",
    "                        \"context\" : context,\n",
    "                        'paragraph_title' : paragraph_title\n",
    "                    })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?</td>\n",
       "      <td>1989년 2월 15일</td>\n",
       "      <td>6548850-0-0</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989년 6월 30일 평양축전에 대표로 파견 된 인물은?</td>\n",
       "      <td>임수경</td>\n",
       "      <td>6548850-0-1</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?</td>\n",
       "      <td>1989년</td>\n",
       "      <td>6548853-0-0</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>임종석을 검거한 장소는 경희대 내 어디인가?</td>\n",
       "      <td>학생회관 건물 계단</td>\n",
       "      <td>6548853-0-1</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임종석이 조사를 받은 뒤 인계된 곳은 어딘가?</td>\n",
       "      <td>서울지방경찰청 공안분실</td>\n",
       "      <td>6548853-0-2</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?</td>\n",
       "      <td>임종석</td>\n",
       "      <td>6332405-0-0</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>임종석이 1989년 2월 15일에 지명수배 받은 혐의는 어떤 시위를 주도했다는 것인가?</td>\n",
       "      <td>여의도 농민 폭력 시위</td>\n",
       "      <td>6332405-0-1</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>정부의 헌법개정안 준비 과정에 대해서 청와대 비서실이 아니라 국무회의 중심으로 이뤄...</td>\n",
       "      <td>허영</td>\n",
       "      <td>6548850-1-0</td>\n",
       "      <td>\"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'행보가 비서 본연의 역할을 벗어난다', '장관들과 내각이 소외되고 대통령비서실의 ...</td>\n",
       "      <td>10차 개헌안 발표</td>\n",
       "      <td>6548850-1-1</td>\n",
       "      <td>\"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>국무회의의 심의를 거쳐야 한다는 헌법 제 몇 조의 내용인가?</td>\n",
       "      <td>제89조</td>\n",
       "      <td>6332405-1-0</td>\n",
       "      <td>\"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다고 지적한 경...</td>\n",
       "      <td>허영</td>\n",
       "      <td>6332405-1-1</td>\n",
       "      <td>\"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...</td>\n",
       "      <td>임종석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>미국 군대 내 두번째로 높은 직위는 무엇인가?</td>\n",
       "      <td>미국 육군 부참모 총장</td>\n",
       "      <td>6521755-0-0</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>로널드 레이건 정부 출범 당시 알렉산더 헤이그는 어떤 직책을 맡았는가?</td>\n",
       "      <td>초대 국무장관직</td>\n",
       "      <td>6521755-0-1</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>알렉산더 헤이그는 어느 대통령의 밑에서 국무장관을 지냈는가?</td>\n",
       "      <td>로널드 레이건 대통령</td>\n",
       "      <td>6521755-0-2</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>로널드 레이건 대통령 밑에서 일한 국무 장관은 누구인가?</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세</td>\n",
       "      <td>6457767-0-0</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>미국 군대에서 두번째로 높은 직위는?</td>\n",
       "      <td>미국 육군 부참모 총장</td>\n",
       "      <td>6457767-0-1</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>알렉산더 메이그스 헤이그의 생년월일은?</td>\n",
       "      <td>1924년 12월 2일</td>\n",
       "      <td>6539187-0-0</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>알렉산더 헤이그가 로널드 레이건 대통령 밑에서 맡은 직책은 무엇이었나?</td>\n",
       "      <td>국무장관</td>\n",
       "      <td>6539187-0-1</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>알렉산더 헤이그가 1984년 발간한 회고록의 제목은 무엇인가?</td>\n",
       "      <td>경고:현실주의, 레이건과 외교 정책</td>\n",
       "      <td>6539187-0-2</td>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>알렉산더 헤이그와 1950년 5월 결혼한 상대의 이름은 무엇인가?</td>\n",
       "      <td>퍼트리샤 앤토이넷 폭스</td>\n",
       "      <td>6521755-1-0</td>\n",
       "      <td>노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국...</td>\n",
       "      <td>알렉산더_헤이그</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question               answer  \\\n",
       "0               임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?         1989년 2월 15일   \n",
       "1                    1989년 6월 30일 평양축전에 대표로 파견 된 인물은?                  임수경   \n",
       "2               임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?                1989년   \n",
       "3                            임종석을 검거한 장소는 경희대 내 어디인가?           학생회관 건물 계단   \n",
       "4                           임종석이 조사를 받은 뒤 인계된 곳은 어딘가?         서울지방경찰청 공안분실   \n",
       "5   1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?                  임종석   \n",
       "6    임종석이 1989년 2월 15일에 지명수배 받은 혐의는 어떤 시위를 주도했다는 것인가?         여의도 농민 폭력 시위   \n",
       "7   정부의 헌법개정안 준비 과정에 대해서 청와대 비서실이 아니라 국무회의 중심으로 이뤄...                   허영   \n",
       "8   '행보가 비서 본연의 역할을 벗어난다', '장관들과 내각이 소외되고 대통령비서실의 ...           10차 개헌안 발표   \n",
       "9                   국무회의의 심의를 거쳐야 한다는 헌법 제 몇 조의 내용인가?                 제89조   \n",
       "10  법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다고 지적한 경...                   허영   \n",
       "11                          미국 군대 내 두번째로 높은 직위는 무엇인가?         미국 육군 부참모 총장   \n",
       "12            로널드 레이건 정부 출범 당시 알렉산더 헤이그는 어떤 직책을 맡았는가?             초대 국무장관직   \n",
       "13                  알렉산더 헤이그는 어느 대통령의 밑에서 국무장관을 지냈는가?          로널드 레이건 대통령   \n",
       "14                    로널드 레이건 대통령 밑에서 일한 국무 장관은 누구인가?     알렉산더 메이그스 헤이그 2세   \n",
       "15                               미국 군대에서 두번째로 높은 직위는?         미국 육군 부참모 총장   \n",
       "16                              알렉산더 메이그스 헤이그의 생년월일은?         1924년 12월 2일   \n",
       "17            알렉산더 헤이그가 로널드 레이건 대통령 밑에서 맡은 직책은 무엇이었나?                 국무장관   \n",
       "18                 알렉산더 헤이그가 1984년 발간한 회고록의 제목은 무엇인가?  경고:현실주의, 레이건과 외교 정책   \n",
       "19               알렉산더 헤이그와 1950년 5월 결혼한 상대의 이름은 무엇인가?         퍼트리샤 앤토이넷 폭스   \n",
       "\n",
       "          qa_id                                            context  \\\n",
       "0   6548850-0-0  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "1   6548850-0-1  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "2   6548853-0-0  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "3   6548853-0-1  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "4   6548853-0-2  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "5   6332405-0-0  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "6   6332405-0-1  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "7   6548850-1-0  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...   \n",
       "8   6548850-1-1  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...   \n",
       "9   6332405-1-0  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...   \n",
       "10  6332405-1-1  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...   \n",
       "11  6521755-0-0  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "12  6521755-0-1  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "13  6521755-0-2  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "14  6457767-0-0  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "15  6457767-0-1  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "16  6539187-0-0  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "17  6539187-0-1  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "18  6539187-0-2  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....   \n",
       "19  6521755-1-0  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국...   \n",
       "\n",
       "   paragraph_title  \n",
       "0              임종석  \n",
       "1              임종석  \n",
       "2              임종석  \n",
       "3              임종석  \n",
       "4              임종석  \n",
       "5              임종석  \n",
       "6              임종석  \n",
       "7              임종석  \n",
       "8              임종석  \n",
       "9              임종석  \n",
       "10             임종석  \n",
       "11        알렉산더_헤이그  \n",
       "12        알렉산더_헤이그  \n",
       "13        알렉산더_헤이그  \n",
       "14        알렉산더_헤이그  \n",
       "15        알렉산더_헤이그  \n",
       "16        알렉산더_헤이그  \n",
       "17        알렉산더_헤이그  \n",
       "18        알렉산더_헤이그  \n",
       "19        알렉산더_헤이그  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./KorQuAD_v1.0_dev.json', 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open('./KorQuAD_v1.0_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "df_dev = korquad_to_dataframe(dev_data)\n",
    "print(df_dev.shape)\n",
    "df_dev.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60407, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'교향곡'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = korquad_to_dataframe(train_data)\n",
    "print(df_train.shape)\n",
    "df_train[\"answer\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  context  answer\n",
       "False     False    False     66181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[[\"question\", \"context\", \"answer\"]]\n",
    "df_dev = df_dev[[\"question\", \"context\", \"answer\"]]\n",
    "\n",
    "df = pd.concat([df_train, df_dev]).reset_index(drop=True)\n",
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.46.1.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.65 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "lora_model = FastLanguageModel.get_peft_model(\n",
    "    model, \n",
    "    r = 16,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\", \n",
    "    use_gradient_checkpointing = \"unsloth\", \n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(row):\n",
    "    prompt = f\"\"\"{row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{row[\"context\"]}\n",
    "###\"\"\"\n",
    "    \n",
    "    message = [\n",
    "        {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\" : \"user\", \"content\" : prompt},\n",
    "        {\"role\" : \"assistant\", \"content\" : row[\"answer\"]}\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(message, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>디시인사이드에서 조사한 \"2008년 올해 최고의 유행어는?\"의 순위에 오른 발언을 ...</td>\n",
       "      <td>2008년 10월 국회에서 열린 국정감사에서 민주당 이종걸 의원의 대통령에 대한 비...</td>\n",
       "      <td>유인촌</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이명박과 박근혜의 회동이 11개월만에 성사된 날은 언제인가?</td>\n",
       "      <td>2010년 8월 22일 이명박과 박근혜의 회동이 11개월만에 성사되었다. 95분동안...</td>\n",
       "      <td>2010년 8월 22일</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>해구 동쪽 지역에서는 어떤 형태의 여진이 발생 중인가?</td>\n",
       "      <td>본진 이후 일어나고 있는 여진은 이와테 현 앞바다부터 이바라키 현 앞바다까지 동서 ...</td>\n",
       "      <td>해양지각 내 지진</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>남쪽 탑에 설치된 스페시오사 종의 무게는 몇 kg인가?</td>\n",
       "      <td>1331년 신랑의 토대가 설치되었고 2년 후인 1333년에 프란체스코 페트라르카가 ...</td>\n",
       "      <td>5,200kg</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>천문학 집대성의 아랍어 역본은?</td>\n",
       "      <td>프톨레마이오스가 알렉산드리아의 그리스 사회 일원이라는 것 외에 삶의 세밀한 부분은 ...</td>\n",
       "      <td>알마게스트</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  디시인사이드에서 조사한 \"2008년 올해 최고의 유행어는?\"의 순위에 오른 발언을 ...   \n",
       "1                  이명박과 박근혜의 회동이 11개월만에 성사된 날은 언제인가?   \n",
       "2                     해구 동쪽 지역에서는 어떤 형태의 여진이 발생 중인가?   \n",
       "3                     남쪽 탑에 설치된 스페시오사 종의 무게는 몇 kg인가?   \n",
       "4                                  천문학 집대성의 아랍어 역본은?   \n",
       "\n",
       "                                             context        answer  \\\n",
       "0  2008년 10월 국회에서 열린 국정감사에서 민주당 이종걸 의원의 대통령에 대한 비...           유인촌   \n",
       "1  2010년 8월 22일 이명박과 박근혜의 회동이 11개월만에 성사되었다. 95분동안...  2010년 8월 22일   \n",
       "2  본진 이후 일어나고 있는 여진은 이와테 현 앞바다부터 이바라키 현 앞바다까지 동서 ...     해양지각 내 지진   \n",
       "3  1331년 신랑의 토대가 설치되었고 2년 후인 1333년에 프란체스코 페트라르카가 ...       5,200kg   \n",
       "4  프톨레마이오스가 알렉산드리아의 그리스 사회 일원이라는 것 외에 삶의 세밀한 부분은 ...         알마게스트   \n",
       "\n",
       "                                                text  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"] = df.apply(format_example, axis=1)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "디시인사이드에서 조사한 \"2008년 올해 최고의 유행어는?\"의 순위에 오른 발언을 한 사람은?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2008년 10월 국회에서 열린 국정감사에서 민주당 이종걸 의원의 대통령에 대한 비난에 대해 정회 후 반발하는 과정에서 기자들에게 손가락질을 하며 \"찍지마! XX 찍지마. 성질이 뻗쳐서 정말\" 이라는 욕설 발언을 하여 크게 비판을 받았다. 당시 수많은 기자들이 있는 상황에서 이 발언이 모두 녹화되었으며 민주당을 비롯한 야당은 유 장관의 이런 행위가 국회를 모독한 것이라며 반드시 책임을 묻겠다고 말하였다. 유 장관은 현장에서 바로 사진 기자들에게 사과를 하고 욕설이 아니었다고 해명자료를 배포했으며, 이틀 후 다시 공식 브리핑을 통해 사과했다. 유인촌이 국정감사장에서 한 발언은 2008년에 디시인사이드에서 조사한 \"2008년 올해 최고의 유행어는?\"의 순위에 오르기도 하였다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "유인촌<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 s, sys: 0 ns, total: 39.5 s\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def count_tokens(row):\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False\n",
    "        )[\"input_ids\"]\n",
    "    )\n",
    "\n",
    "\n",
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(57139, 66181, 0.8633746845771445)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "plt.hist(df[\"token_count\"], ec=\"k\", bins=30, \n",
    "         weights=np.ones(len(df[\"token_count\"])) / len(df[\"token_count\"]))\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "len(df[df[\"token_count\"] < 512]), len(df), len(df[df['token_count'] < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "# 토큰 길이로 적당히 학습 샘플 서브샘플링 \n",
    "df_sampled = df[df[\"token_count\"] < 512]\n",
    "df_sampled = df_sampled.sample(6000, random_state=SEED)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df_sampled, test_size=0.2, random_state=SEED)\n",
    "val, test = train_test_split(temp, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data ratio:0.8, 4800\n",
      "Valid data ratio:0.16, 960\n",
      "Test data ratio:0.04, 240\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data ratio:{len(train) / len(df_sampled)}, {len(train)}\")\n",
    "print(f\"Valid data ratio:{len(val) / len(df_sampled)}, {len(val)}\")\n",
    "print(f\"Test data ratio:{len(test) / len(df_sampled)}, {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=4000, random_state=SEED).to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=500, random_state=SEED).to_json(\"val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=100, random_state=SEED).to_json(\"test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\" : \"train.json\",\n",
    "        \"validation\" : \"val.json\",\n",
    "        \"test\" : \"test.json\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = f\"\"\"{data_row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{data_row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    ) # 프롬프트 끝에 <|start_header_id|>assistant<|end_header_id|> 를 붙이게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_test_one_sample(example, model):\n",
    "    prompt = create_test_prompt(example)\n",
    "    print(\"\\nPROMPT\\n\", prompt.strip())\n",
    "\n",
    "    inputs = torch.tensor(\n",
    "        [tokenizer(prompt)[\"input_ids\"]]\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids = inputs,\n",
    "        max_new_tokens = 64,\n",
    "        use_cache = True,\n",
    "        temperature = 1.5,\n",
    "        min_p = 0.1\n",
    "    )\n",
    "\n",
    "    print(\"\\nANS\\n\", example[\"answer\"])\n",
    "    print(\"\\nPred\\n\", tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip())\n",
    "\n",
    "    return example['answer'], tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip()\n",
    "\n",
    "FastLanguageModel.for_inference(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "베리가 사용했던 기타는 무엇인가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1970년대의 베리는 그의 초기 성공이 뒷받침되어 투어를 성사시켰다. 그는 수년간 깁슨 기타를 짊어지고 어디로 가든 밴드가 자신의 음악을 알고 있을 것이라고 확신하면서 이들을 고용하며 먼 길을 떠났다. 올뮤직은 이 시기 그의 \"라이브 공연은 계속해서 불규칙해졌다 ... 끔찍한 백업 밴드와 협연하여 설렁하며, 가락 안 맞는 공연을 보여줬다.\"면서 그의 명성에 먹칠을 했다고 평론했다. 1972년 3월에는 쉐퍼드 부시에 위치한 BBC 텔레비전 시어터에서, 밴드 라킹 호스(Rocking Horse)가 백업한 60일의 투어 중 일부인 《척 베리 인 콘서트》를 위해 영화를 찍는다. 1970년대 그와 함께한 수많은 백업 뮤지션 중에서는 막 음악을 시작한 브루스 스프링스틴과 스티브 밀러가 있었다. 스프링스틴은 다큐멘터리 영화 《헤일! 헤일! 로큰롤》에서 베리가 밴드에게 세트 리스트를 주지 않았으며, 그는 자신의 기타 인트로를 듣고 그들이 알아서 자신에게 따라올 것이라 기대했다고 말했다. 베리는 공연 이후 밴드에게 고맙다는 인사 하나 없었다. 그렇지만, 스프링스틴은 그가 1995년에 로큰롤 명예의 전당 콘서트를 할 때 베리의 백업을 다시금 맡아주었다. 지미 카터의 요청에 의해 베리는 1979년 6월 1일 백악관에서 공연하기도 했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANS\n",
      " 깁슨 기타\n",
      "\n",
      "Pred\n",
      " 그의 밴드에 밴드 \"로킹 호스(Rocking Horse)\"의 가ît로, 1972년 3월 BBC 텔레비전 시어터에서, 1970년대 그와 함께한 수많은 백업 뮤지션 중에서도, 막\n"
     ]
    }
   ],
   "source": [
    "# Append\n",
    "untrained = []\n",
    "untrained.append(\n",
    "    int_test_one_sample(dataset[\"test\"][0], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "일본의 공식 웹사이트에 바이오하자드 엄브렐러 크로니클즈 티저 영상이 공개된 날짜는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2006년 11월 3일에 열린 닌텐도 월드에서는 2007년에 발매될 예정이라는 발표와 함께 게임의 영상이 공개되었다. 2007년 4월 6일에는 일본의 공식 웹사이트에서 티저 영상을 공개하였다. 이어서 2007년 4월 13일에는 캐릭터 프로필과 스크린샷이 포함된 두 번째 트레일러가 공개되었다. 캡콤의 기획 및 조사 디렉터 크리스티안 스벤슨은 게임이 480의 순차 주사 방식과 16:9의 와이드스크린을 지원할 것이라고 언급하였다. 《바이오하자드 4 위 에디션》에도 특전 영상으로 트레일러가 포함되어 있는데, 여기에 포함된 영상은 오리지널의 양관과 라쿤 시의 일부 지역을 보여주었다. 2007년 7월 11일의 E3에서 닌텐도 측은 총 악세사리인 Wii 재퍼를 게임에서 사용할 수 있다고 언급하였다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 2007년 4월 6일\n",
      "\n",
      "Pred\n",
      " 2007년 4월 6일 일본의 공식 웹사이트에서 TIzer 영상을 공개하였다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    int_test_one_sample(dataset['test'][1], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "폰티액전쟁을 학살의 광기로 묘사한 사학자는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "영국 정착민과 인디언과의 관계는, 프렌치 인디언 전쟁 때 극도의 긴장 관계에 있었지만, 폰티액 전쟁 동안에 오히려 완화됐다. 사학자 데이비드 딕슨은 “폰티액 전쟁은 양측 모두 학살의 광기에 취해 버린 듯, 그 무서운 폭력이 전례가 없던 것이었다.”고 평가했다. 사학자 다니엘 리히터는 인디언이 영국군을 몰아내려는 한 것과 팩스턴 보이즈가 백인 사회에서 인디언을 없애려고 한 것을 인종 청소의 예라고 생각했다. 전쟁에 관련된 양측 모두 정착민과 원주민은 본질적으로 다르며, 공생할 수 없다는 결론에 도달했다. 리히터는 이 전쟁이 “모든 원주민은 ‘인디언’이고 각 유럽계 미국인은 ‘백인’이며, 한쪽은 다른 한쪽을 파괴하기 위해 결속하는 새로운 사고방식을 가져 오게 되었다.”고 평했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 데이비드 딕슨\n",
      "\n",
      "Pred\n",
      " 다니엘 리히터<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    int_test_one_sample(dataset['test'][2], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "쿠빌라이와 동맹을 맺고나서 카이두가 아리크 부케를 도왔다는 구실로 카이두를 공격한 인물은?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1259년, 몽케 칸이 남송 원정 중 사망하자 다음 해인 1260년에 그의 동생인 쿠빌라이와 아리크 부케가 각각 대칸을 칭했다. 서로 대칸을 칭한 쿠빌라이와 아리크 부케는 곧바로 전쟁에 들어갔다. 전쟁은 중국 북부의 풍부한 물자를 가진 쿠빌라이에게 시종일관 유리하게 진행됐다. 이에 아리크 부케는 자신이 임명한 차가타이 칸국의 알루구에게 도움을 요청했지만 알루구는 이 요청을 거절하고 오히려 1263년에 쿠빌라이와 동맹을 맺었다. 쿠빌라이와 동맹을 맺은 알루구는 카이두가 아리크 부케를 도왔다는 구실로 카이두를 공격했다. 알루구의 공격을 받은 카이두는 킵차크 칸국의 베르케의 지원을 받아 차가타이 칸국의 영토로 침입하여 알루구와의 전투에서 승리를 거두었으나 다음 번 전투에서 반격을 당해 본국으로 철수했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 알루구\n",
      "\n",
      "Pred\n",
      " 알루구<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    int_test_one_sample(dataset['test'][3], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('깁슨 기타',\n",
       "  '그의 밴드에 밴드 \"로킹 호스(Rocking Horse)\"의 가ît로, 1972년 3월 BBC 텔레비전 시어터에서, 1970년대 그와 함께한 수많은 백업 뮤지션 중에서도, 막'),\n",
       " ('2007년 4월 6일', '2007년 4월 6일 일본의 공식 웹사이트에서 TIzer 영상을 공개하였다.<|eot_id|>'),\n",
       " ('데이비드 딕슨', '다니엘 리히터<|eot_id|>'),\n",
       " ('알루구', '알루구<|eot_id|>')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(lora_model);\n",
    "FastLanguageModel.for_training(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 7732.57 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 7637.00 examples/s]\n",
      "/home/mgyukim/.conda/envs/llama/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 5524.35 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 5363.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = lora_model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"validation\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 1,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.2,\n",
    "        save_steps=0.2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 4,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 08:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.238357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.192190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.182273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.233200</td>\n",
       "      <td>0.170069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.165058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained = []\n",
    "FastLanguageModel.for_inference(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "베리가 사용했던 기타는 무엇인가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1970년대의 베리는 그의 초기 성공이 뒷받침되어 투어를 성사시켰다. 그는 수년간 깁슨 기타를 짊어지고 어디로 가든 밴드가 자신의 음악을 알고 있을 것이라고 확신하면서 이들을 고용하며 먼 길을 떠났다. 올뮤직은 이 시기 그의 \"라이브 공연은 계속해서 불규칙해졌다 ... 끔찍한 백업 밴드와 협연하여 설렁하며, 가락 안 맞는 공연을 보여줬다.\"면서 그의 명성에 먹칠을 했다고 평론했다. 1972년 3월에는 쉐퍼드 부시에 위치한 BBC 텔레비전 시어터에서, 밴드 라킹 호스(Rocking Horse)가 백업한 60일의 투어 중 일부인 《척 베리 인 콘서트》를 위해 영화를 찍는다. 1970년대 그와 함께한 수많은 백업 뮤지션 중에서는 막 음악을 시작한 브루스 스프링스틴과 스티브 밀러가 있었다. 스프링스틴은 다큐멘터리 영화 《헤일! 헤일! 로큰롤》에서 베리가 밴드에게 세트 리스트를 주지 않았으며, 그는 자신의 기타 인트로를 듣고 그들이 알아서 자신에게 따라올 것이라 기대했다고 말했다. 베리는 공연 이후 밴드에게 고맙다는 인사 하나 없었다. 그렇지만, 스프링스틴은 그가 1995년에 로큰롤 명예의 전당 콘서트를 할 때 베리의 백업을 다시금 맡아주었다. 지미 카터의 요청에 의해 베리는 1979년 6월 1일 백악관에서 공연하기도 했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 깁슨 기타\n",
      "\n",
      "Pred\n",
      " 깁슨<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][0], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "일본의 공식 웹사이트에 바이오하자드 엄브렐러 크로니클즈 티저 영상이 공개된 날짜는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2006년 11월 3일에 열린 닌텐도 월드에서는 2007년에 발매될 예정이라는 발표와 함께 게임의 영상이 공개되었다. 2007년 4월 6일에는 일본의 공식 웹사이트에서 티저 영상을 공개하였다. 이어서 2007년 4월 13일에는 캐릭터 프로필과 스크린샷이 포함된 두 번째 트레일러가 공개되었다. 캡콤의 기획 및 조사 디렉터 크리스티안 스벤슨은 게임이 480의 순차 주사 방식과 16:9의 와이드스크린을 지원할 것이라고 언급하였다. 《바이오하자드 4 위 에디션》에도 특전 영상으로 트레일러가 포함되어 있는데, 여기에 포함된 영상은 오리지널의 양관과 라쿤 시의 일부 지역을 보여주었다. 2007년 7월 11일의 E3에서 닌텐도 측은 총 악세사리인 Wii 재퍼를 게임에서 사용할 수 있다고 언급하였다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 2007년 4월 6일\n",
      "\n",
      "Pred\n",
      " 2007년 4월 6일<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][1], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "폰티액전쟁을 학살의 광기로 묘사한 사학자는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "영국 정착민과 인디언과의 관계는, 프렌치 인디언 전쟁 때 극도의 긴장 관계에 있었지만, 폰티액 전쟁 동안에 오히려 완화됐다. 사학자 데이비드 딕슨은 “폰티액 전쟁은 양측 모두 학살의 광기에 취해 버린 듯, 그 무서운 폭력이 전례가 없던 것이었다.”고 평가했다. 사학자 다니엘 리히터는 인디언이 영국군을 몰아내려는 한 것과 팩스턴 보이즈가 백인 사회에서 인디언을 없애려고 한 것을 인종 청소의 예라고 생각했다. 전쟁에 관련된 양측 모두 정착민과 원주민은 본질적으로 다르며, 공생할 수 없다는 결론에 도달했다. 리히터는 이 전쟁이 “모든 원주민은 ‘인디언’이고 각 유럽계 미국인은 ‘백인’이며, 한쪽은 다른 한쪽을 파괴하기 위해 결속하는 새로운 사고방식을 가져 오게 되었다.”고 평했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 데이비드 딕슨\n",
      "\n",
      "Pred\n",
      " 데이비드 딕슨<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][2], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "쿠빌라이와 동맹을 맺고나서 카이두가 아리크 부케를 도왔다는 구실로 카이두를 공격한 인물은?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1259년, 몽케 칸이 남송 원정 중 사망하자 다음 해인 1260년에 그의 동생인 쿠빌라이와 아리크 부케가 각각 대칸을 칭했다. 서로 대칸을 칭한 쿠빌라이와 아리크 부케는 곧바로 전쟁에 들어갔다. 전쟁은 중국 북부의 풍부한 물자를 가진 쿠빌라이에게 시종일관 유리하게 진행됐다. 이에 아리크 부케는 자신이 임명한 차가타이 칸국의 알루구에게 도움을 요청했지만 알루구는 이 요청을 거절하고 오히려 1263년에 쿠빌라이와 동맹을 맺었다. 쿠빌라이와 동맹을 맺은 알루구는 카이두가 아리크 부케를 도왔다는 구실로 카이두를 공격했다. 알루구의 공격을 받은 카이두는 킵차크 칸국의 베르케의 지원을 받아 차가타이 칸국의 영토로 침입하여 알루구와의 전투에서 승리를 거두었으나 다음 번 전투에서 반격을 당해 본국으로 철수했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 알루구\n",
      "\n",
      "Pred\n",
      " 알루구<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][3], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정답</th>\n",
       "      <th>학습전 출력</th>\n",
       "      <th>학습후 출력</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>깁슨 기타</td>\n",
       "      <td>그의 밴드에 밴드 \"로킹 호스(Rocking Horse)\"의 가ît로, 1972년 ...</td>\n",
       "      <td>깁슨&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007년 4월 6일</td>\n",
       "      <td>2007년 4월 6일 일본의 공식 웹사이트에서 TIzer 영상을 공개하였다.&lt;|eo...</td>\n",
       "      <td>2007년 4월 6일&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>데이비드 딕슨</td>\n",
       "      <td>다니엘 리히터&lt;|eot_id|&gt;</td>\n",
       "      <td>데이비드 딕슨&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>알루구</td>\n",
       "      <td>알루구&lt;|eot_id|&gt;</td>\n",
       "      <td>알루구&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            정답                                             학습전 출력  \\\n",
       "0        깁슨 기타  그의 밴드에 밴드 \"로킹 호스(Rocking Horse)\"의 가ît로, 1972년 ...   \n",
       "1  2007년 4월 6일  2007년 4월 6일 일본의 공식 웹사이트에서 TIzer 영상을 공개하였다.<|eo...   \n",
       "2      데이비드 딕슨                                  다니엘 리히터<|eot_id|>   \n",
       "3          알루구                                      알루구<|eot_id|>   \n",
       "\n",
       "                  학습후 출력  \n",
       "0           깁슨<|eot_id|>  \n",
       "1  2007년 4월 6일<|eot_id|>  \n",
       "2      데이비드 딕슨<|eot_id|>  \n",
       "3          알루구<|eot_id|>  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[(utrd[0], utrd[1], trd[1]) for utrd, trd in zip(untrained, trained)],\n",
    "    columns=['정답', '학습전 출력', '학습후 출력']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
