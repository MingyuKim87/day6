{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgyukim/.conda/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_train.json -O KorQuAD_v1.0_train.json\n",
    "#!wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_dev.json -O KorQuAD_v1.0_dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def korquad_to_dataframe(data):\n",
    "    rows = []\n",
    "    for paragraph in data[\"data\"]:\n",
    "        paragraph_title = paragraph[\"title\"]\n",
    "\n",
    "        for qa in paragraph[\"paragraphs\"]:\n",
    "            context = qa[\"context\"]\n",
    "\n",
    "            for question in qa[\"qas\"]:\n",
    "                q = question[\"question\"]\n",
    "                qa_id = question[\"id\"]\n",
    "\n",
    "                for answer in question[\"answers\"]:\n",
    "                    a = answer[\"text\"]\n",
    "                    rows.append({\n",
    "                        'question' : q,\n",
    "                        'answer' : a,\n",
    "                        'qa_id' : qa_id,\n",
    "                        \"context\" : context,\n",
    "                        'paragraph_title' : paragraph_title\n",
    "                    })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì„ì¢…ì„ì´ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°° ëœ ë‚ ì€?</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼</td>\n",
       "      <td>6548850-0-0</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989ë…„ 6ì›” 30ì¼ í‰ì–‘ì¶•ì „ì— ëŒ€í‘œë¡œ íŒŒê²¬ ëœ ì¸ë¬¼ì€?</td>\n",
       "      <td>ì„ìˆ˜ê²½</td>\n",
       "      <td>6548850-0-1</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì„ì¢…ì„ì´ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°°ëœ ì—°ë„ëŠ”?</td>\n",
       "      <td>1989ë…„</td>\n",
       "      <td>6548853-0-0</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì„ì¢…ì„ì„ ê²€ê±°í•œ ì¥ì†ŒëŠ” ê²½í¬ëŒ€ ë‚´ ì–´ë””ì¸ê°€?</td>\n",
       "      <td>í•™ìƒíšŒê´€ ê±´ë¬¼ ê³„ë‹¨</td>\n",
       "      <td>6548853-0-1</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì„ì¢…ì„ì´ ì¡°ì‚¬ë¥¼ ë°›ì€ ë’¤ ì¸ê³„ëœ ê³³ì€ ì–´ë”˜ê°€?</td>\n",
       "      <td>ì„œìš¸ì§€ë°©ê²½ì°°ì²­ ê³µì•ˆë¶„ì‹¤</td>\n",
       "      <td>6548853-0-2</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°°ëœ ì‚¬ëŒì˜ ì´ë¦„ì€?</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "      <td>6332405-0-0</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ì„ì¢…ì„ì´ 1989ë…„ 2ì›” 15ì¼ì— ì§€ëª…ìˆ˜ë°° ë°›ì€ í˜ì˜ëŠ” ì–´ë–¤ ì‹œìœ„ë¥¼ ì£¼ë„í–ˆë‹¤ëŠ” ê²ƒì¸ê°€?</td>\n",
       "      <td>ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„</td>\n",
       "      <td>6332405-0-1</td>\n",
       "      <td>1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ì •ë¶€ì˜ í—Œë²•ê°œì •ì•ˆ ì¤€ë¹„ ê³¼ì •ì— ëŒ€í•´ì„œ ì²­ì™€ëŒ€ ë¹„ì„œì‹¤ì´ ì•„ë‹ˆë¼ êµ­ë¬´íšŒì˜ ì¤‘ì‹¬ìœ¼ë¡œ ì´ë¤„...</td>\n",
       "      <td>í—ˆì˜</td>\n",
       "      <td>6548850-1-0</td>\n",
       "      <td>\"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜ ì—­í• ì„ ë²—ì–´ë‚œë‹¤', 'ì¥ê´€ë“¤ê³¼ ë‚´ê°ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ...</td>\n",
       "      <td>10ì°¨ ê°œí—Œì•ˆ ë°œí‘œ</td>\n",
       "      <td>6548850-1-1</td>\n",
       "      <td>\"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>êµ­ë¬´íšŒì˜ì˜ ì‹¬ì˜ë¥¼ ê±°ì³ì•¼ í•œë‹¤ëŠ” í—Œë²• ì œ ëª‡ ì¡°ì˜ ë‚´ìš©ì¸ê°€?</td>\n",
       "      <td>ì œ89ì¡°</td>\n",
       "      <td>6332405-1-0</td>\n",
       "      <td>\"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ë²•ë¬´ë¶€ ì¥ê´€ì„ ì œì³ë†“ê³  ë¯¼ì •ìˆ˜ì„ì´ ê°œì •ì•ˆì„ ì„¤ëª…í•˜ëŠ” ê²Œ ì´í•´ê°€ ì•ˆ ëœë‹¤ê³  ì§€ì í•œ ê²½...</td>\n",
       "      <td>í—ˆì˜</td>\n",
       "      <td>6332405-1-1</td>\n",
       "      <td>\"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...</td>\n",
       "      <td>ì„ì¢…ì„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ë¯¸êµ­ êµ°ëŒ€ ë‚´ ë‘ë²ˆì§¸ë¡œ ë†’ì€ ì§ìœ„ëŠ” ë¬´ì—‡ì¸ê°€?</td>\n",
       "      <td>ë¯¸êµ­ ìœ¡êµ° ë¶€ì°¸ëª¨ ì´ì¥</td>\n",
       "      <td>6521755-0-0</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ë¡œë„ë“œ ë ˆì´ê±´ ì •ë¶€ ì¶œë²” ë‹¹ì‹œ ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ëŠ” ì–´ë–¤ ì§ì±…ì„ ë§¡ì•˜ëŠ”ê°€?</td>\n",
       "      <td>ì´ˆëŒ€ êµ­ë¬´ì¥ê´€ì§</td>\n",
       "      <td>6521755-0-1</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ëŠ” ì–´ëŠ ëŒ€í†µë ¹ì˜ ë°‘ì—ì„œ êµ­ë¬´ì¥ê´€ì„ ì§€ëƒˆëŠ”ê°€?</td>\n",
       "      <td>ë¡œë„ë“œ ë ˆì´ê±´ ëŒ€í†µë ¹</td>\n",
       "      <td>6521755-0-2</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ë¡œë„ë“œ ë ˆì´ê±´ ëŒ€í†µë ¹ ë°‘ì—ì„œ ì¼í•œ êµ­ë¬´ ì¥ê´€ì€ ëˆ„êµ¬ì¸ê°€?</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸</td>\n",
       "      <td>6457767-0-0</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ë¯¸êµ­ êµ°ëŒ€ì—ì„œ ë‘ë²ˆì§¸ë¡œ ë†’ì€ ì§ìœ„ëŠ”?</td>\n",
       "      <td>ë¯¸êµ­ ìœ¡êµ° ë¶€ì°¸ëª¨ ì´ì¥</td>\n",
       "      <td>6457767-0-1</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ì˜ ìƒë…„ì›”ì¼ì€?</td>\n",
       "      <td>1924ë…„ 12ì›” 2ì¼</td>\n",
       "      <td>6539187-0-0</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ê°€ ë¡œë„ë“œ ë ˆì´ê±´ ëŒ€í†µë ¹ ë°‘ì—ì„œ ë§¡ì€ ì§ì±…ì€ ë¬´ì—‡ì´ì—ˆë‚˜?</td>\n",
       "      <td>êµ­ë¬´ì¥ê´€</td>\n",
       "      <td>6539187-0-1</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ê°€ 1984ë…„ ë°œê°„í•œ íšŒê³ ë¡ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€?</td>\n",
       "      <td>ê²½ê³ :í˜„ì‹¤ì£¼ì˜, ë ˆì´ê±´ê³¼ ì™¸êµ ì •ì±…</td>\n",
       "      <td>6539187-0-2</td>\n",
       "      <td>ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ì™€ 1950ë…„ 5ì›” ê²°í˜¼í•œ ìƒëŒ€ì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€?</td>\n",
       "      <td>í¼íŠ¸ë¦¬ìƒ¤ ì•¤í† ì´ë„· í­ìŠ¤</td>\n",
       "      <td>6521755-1-0</td>\n",
       "      <td>ë…¸í„°ë°ì„ ëŒ€í•™êµì—ì„œ 2ë…„ê°„ í•©ë¦¬ì ìœ¼ë¡œ ì‹¬ê°í•œ ê³µë¶€ë¥¼ í•œ í›„ í—¤ì´ê·¸ëŠ” 1944ë…„ ë¯¸êµ­...</td>\n",
       "      <td>ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question               answer  \\\n",
       "0               ì„ì¢…ì„ì´ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°° ëœ ë‚ ì€?         1989ë…„ 2ì›” 15ì¼   \n",
       "1                    1989ë…„ 6ì›” 30ì¼ í‰ì–‘ì¶•ì „ì— ëŒ€í‘œë¡œ íŒŒê²¬ ëœ ì¸ë¬¼ì€?                  ì„ìˆ˜ê²½   \n",
       "2               ì„ì¢…ì„ì´ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°°ëœ ì—°ë„ëŠ”?                1989ë…„   \n",
       "3                            ì„ì¢…ì„ì„ ê²€ê±°í•œ ì¥ì†ŒëŠ” ê²½í¬ëŒ€ ë‚´ ì–´ë””ì¸ê°€?           í•™ìƒíšŒê´€ ê±´ë¬¼ ê³„ë‹¨   \n",
       "4                           ì„ì¢…ì„ì´ ì¡°ì‚¬ë¥¼ ë°›ì€ ë’¤ ì¸ê³„ëœ ê³³ì€ ì–´ë”˜ê°€?         ì„œìš¸ì§€ë°©ê²½ì°°ì²­ ê³µì•ˆë¶„ì‹¤   \n",
       "5   1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°°ëœ ì‚¬ëŒì˜ ì´ë¦„ì€?                  ì„ì¢…ì„   \n",
       "6    ì„ì¢…ì„ì´ 1989ë…„ 2ì›” 15ì¼ì— ì§€ëª…ìˆ˜ë°° ë°›ì€ í˜ì˜ëŠ” ì–´ë–¤ ì‹œìœ„ë¥¼ ì£¼ë„í–ˆë‹¤ëŠ” ê²ƒì¸ê°€?         ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„   \n",
       "7   ì •ë¶€ì˜ í—Œë²•ê°œì •ì•ˆ ì¤€ë¹„ ê³¼ì •ì— ëŒ€í•´ì„œ ì²­ì™€ëŒ€ ë¹„ì„œì‹¤ì´ ì•„ë‹ˆë¼ êµ­ë¬´íšŒì˜ ì¤‘ì‹¬ìœ¼ë¡œ ì´ë¤„...                   í—ˆì˜   \n",
       "8   'í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜ ì—­í• ì„ ë²—ì–´ë‚œë‹¤', 'ì¥ê´€ë“¤ê³¼ ë‚´ê°ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ...           10ì°¨ ê°œí—Œì•ˆ ë°œí‘œ   \n",
       "9                   êµ­ë¬´íšŒì˜ì˜ ì‹¬ì˜ë¥¼ ê±°ì³ì•¼ í•œë‹¤ëŠ” í—Œë²• ì œ ëª‡ ì¡°ì˜ ë‚´ìš©ì¸ê°€?                 ì œ89ì¡°   \n",
       "10  ë²•ë¬´ë¶€ ì¥ê´€ì„ ì œì³ë†“ê³  ë¯¼ì •ìˆ˜ì„ì´ ê°œì •ì•ˆì„ ì„¤ëª…í•˜ëŠ” ê²Œ ì´í•´ê°€ ì•ˆ ëœë‹¤ê³  ì§€ì í•œ ê²½...                   í—ˆì˜   \n",
       "11                          ë¯¸êµ­ êµ°ëŒ€ ë‚´ ë‘ë²ˆì§¸ë¡œ ë†’ì€ ì§ìœ„ëŠ” ë¬´ì—‡ì¸ê°€?         ë¯¸êµ­ ìœ¡êµ° ë¶€ì°¸ëª¨ ì´ì¥   \n",
       "12            ë¡œë„ë“œ ë ˆì´ê±´ ì •ë¶€ ì¶œë²” ë‹¹ì‹œ ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ëŠ” ì–´ë–¤ ì§ì±…ì„ ë§¡ì•˜ëŠ”ê°€?             ì´ˆëŒ€ êµ­ë¬´ì¥ê´€ì§   \n",
       "13                  ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ëŠ” ì–´ëŠ ëŒ€í†µë ¹ì˜ ë°‘ì—ì„œ êµ­ë¬´ì¥ê´€ì„ ì§€ëƒˆëŠ”ê°€?          ë¡œë„ë“œ ë ˆì´ê±´ ëŒ€í†µë ¹   \n",
       "14                    ë¡œë„ë“œ ë ˆì´ê±´ ëŒ€í†µë ¹ ë°‘ì—ì„œ ì¼í•œ êµ­ë¬´ ì¥ê´€ì€ ëˆ„êµ¬ì¸ê°€?     ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸   \n",
       "15                               ë¯¸êµ­ êµ°ëŒ€ì—ì„œ ë‘ë²ˆì§¸ë¡œ ë†’ì€ ì§ìœ„ëŠ”?         ë¯¸êµ­ ìœ¡êµ° ë¶€ì°¸ëª¨ ì´ì¥   \n",
       "16                              ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ì˜ ìƒë…„ì›”ì¼ì€?         1924ë…„ 12ì›” 2ì¼   \n",
       "17            ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ê°€ ë¡œë„ë“œ ë ˆì´ê±´ ëŒ€í†µë ¹ ë°‘ì—ì„œ ë§¡ì€ ì§ì±…ì€ ë¬´ì—‡ì´ì—ˆë‚˜?                 êµ­ë¬´ì¥ê´€   \n",
       "18                 ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ê°€ 1984ë…„ ë°œê°„í•œ íšŒê³ ë¡ì˜ ì œëª©ì€ ë¬´ì—‡ì¸ê°€?  ê²½ê³ :í˜„ì‹¤ì£¼ì˜, ë ˆì´ê±´ê³¼ ì™¸êµ ì •ì±…   \n",
       "19               ì•Œë ‰ì‚°ë” í—¤ì´ê·¸ì™€ 1950ë…„ 5ì›” ê²°í˜¼í•œ ìƒëŒ€ì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€?         í¼íŠ¸ë¦¬ìƒ¤ ì•¤í† ì´ë„· í­ìŠ¤   \n",
       "\n",
       "          qa_id                                            context  \\\n",
       "0   6548850-0-0  1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...   \n",
       "1   6548850-0-1  1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...   \n",
       "2   6548853-0-0  1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...   \n",
       "3   6548853-0-1  1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...   \n",
       "4   6548853-0-2  1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...   \n",
       "5   6332405-0-0  1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...   \n",
       "6   6332405-0-1  1989ë…„ 2ì›” 15ì¼ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜(í­ë ¥í–‰ìœ„ë“±ì²˜ë²Œì—ê´€í•œë²•ë¥ ...   \n",
       "7   6548850-1-0  \"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...   \n",
       "8   6548850-1-1  \"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...   \n",
       "9   6332405-1-0  \"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...   \n",
       "10  6332405-1-1  \"ë‚´ê°ê³¼ ì¥ê´€ë“¤ì´ ì†Œì™¸ë˜ê³  ëŒ€í†µë ¹ë¹„ì„œì‹¤ì˜ ê¶Œí•œì´ ë„ˆë¬´ í¬ë‹¤\", \"í–‰ë³´ê°€ ë¹„ì„œ ë³¸ì—°ì˜...   \n",
       "11  6521755-0-0  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "12  6521755-0-1  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "13  6521755-0-2  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "14  6457767-0-0  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "15  6457767-0-1  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "16  6539187-0-0  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "17  6539187-0-1  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "18  6539187-0-2  ì•Œë ‰ì‚°ë” ë©”ì´ê·¸ìŠ¤ í—¤ì´ê·¸ 2ì„¸(ì˜ì–´: Alexander Meigs Haig, Jr....   \n",
       "19  6521755-1-0  ë…¸í„°ë°ì„ ëŒ€í•™êµì—ì„œ 2ë…„ê°„ í•©ë¦¬ì ìœ¼ë¡œ ì‹¬ê°í•œ ê³µë¶€ë¥¼ í•œ í›„ í—¤ì´ê·¸ëŠ” 1944ë…„ ë¯¸êµ­...   \n",
       "\n",
       "   paragraph_title  \n",
       "0              ì„ì¢…ì„  \n",
       "1              ì„ì¢…ì„  \n",
       "2              ì„ì¢…ì„  \n",
       "3              ì„ì¢…ì„  \n",
       "4              ì„ì¢…ì„  \n",
       "5              ì„ì¢…ì„  \n",
       "6              ì„ì¢…ì„  \n",
       "7              ì„ì¢…ì„  \n",
       "8              ì„ì¢…ì„  \n",
       "9              ì„ì¢…ì„  \n",
       "10             ì„ì¢…ì„  \n",
       "11        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "12        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "13        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "14        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "15        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "16        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "17        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "18        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  \n",
       "19        ì•Œë ‰ì‚°ë”_í—¤ì´ê·¸  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./KorQuAD_v1.0_dev.json', 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open('./KorQuAD_v1.0_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "df_dev = korquad_to_dataframe(dev_data)\n",
    "print(df_dev.shape)\n",
    "df_dev.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60407, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'êµí–¥ê³¡'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = korquad_to_dataframe(train_data)\n",
    "print(df_train.shape)\n",
    "df_train[\"answer\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  context  answer\n",
       "False     False    False     66181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[[\"question\", \"context\", \"answer\"]]\n",
    "df_dev = df_dev[[\"question\", \"context\", \"answer\"]]\n",
    "\n",
    "df = pd.concat([df_train, df_dev]).reset_index(drop=True)\n",
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.46.1.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.65 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "lora_model = FastLanguageModel.get_peft_model(\n",
    "    model, \n",
    "    r = 16,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\", \n",
    "    use_gradient_checkpointing = \"unsloth\", \n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(row):\n",
    "    prompt = f\"\"\"{row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{row[\"context\"]}\n",
    "###\"\"\"\n",
    "    \n",
    "    message = [\n",
    "        {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\" : \"user\", \"content\" : prompt},\n",
    "        {\"role\" : \"assistant\", \"content\" : row[\"answer\"]}\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(message, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë””ì‹œì¸ì‚¬ì´ë“œì—ì„œ ì¡°ì‚¬í•œ \"2008ë…„ ì˜¬í•´ ìµœê³ ì˜ ìœ í–‰ì–´ëŠ”?\"ì˜ ìˆœìœ„ì— ì˜¤ë¥¸ ë°œì–¸ì„ ...</td>\n",
       "      <td>2008ë…„ 10ì›” êµ­íšŒì—ì„œ ì—´ë¦° êµ­ì •ê°ì‚¬ì—ì„œ ë¯¼ì£¼ë‹¹ ì´ì¢…ê±¸ ì˜ì›ì˜ ëŒ€í†µë ¹ì— ëŒ€í•œ ë¹„...</td>\n",
       "      <td>ìœ ì¸ì´Œ</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì´ëª…ë°•ê³¼ ë°•ê·¼í˜œì˜ íšŒë™ì´ 11ê°œì›”ë§Œì— ì„±ì‚¬ëœ ë‚ ì€ ì–¸ì œì¸ê°€?</td>\n",
       "      <td>2010ë…„ 8ì›” 22ì¼ ì´ëª…ë°•ê³¼ ë°•ê·¼í˜œì˜ íšŒë™ì´ 11ê°œì›”ë§Œì— ì„±ì‚¬ë˜ì—ˆë‹¤. 95ë¶„ë™ì•ˆ...</td>\n",
       "      <td>2010ë…„ 8ì›” 22ì¼</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>í•´êµ¬ ë™ìª½ ì§€ì—­ì—ì„œëŠ” ì–´ë–¤ í˜•íƒœì˜ ì—¬ì§„ì´ ë°œìƒ ì¤‘ì¸ê°€?</td>\n",
       "      <td>ë³¸ì§„ ì´í›„ ì¼ì–´ë‚˜ê³  ìˆëŠ” ì—¬ì§„ì€ ì´ì™€í…Œ í˜„ ì•ë°”ë‹¤ë¶€í„° ì´ë°”ë¼í‚¤ í˜„ ì•ë°”ë‹¤ê¹Œì§€ ë™ì„œ ...</td>\n",
       "      <td>í•´ì–‘ì§€ê° ë‚´ ì§€ì§„</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë‚¨ìª½ íƒ‘ì— ì„¤ì¹˜ëœ ìŠ¤í˜ì‹œì˜¤ì‚¬ ì¢…ì˜ ë¬´ê²ŒëŠ” ëª‡ kgì¸ê°€?</td>\n",
       "      <td>1331ë…„ ì‹ ë‘ì˜ í† ëŒ€ê°€ ì„¤ì¹˜ë˜ì—ˆê³  2ë…„ í›„ì¸ 1333ë…„ì— í”„ë€ì²´ìŠ¤ì½” í˜íŠ¸ë¼ë¥´ì¹´ê°€ ...</td>\n",
       "      <td>5,200kg</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì²œë¬¸í•™ ì§‘ëŒ€ì„±ì˜ ì•„ëì–´ ì—­ë³¸ì€?</td>\n",
       "      <td>í”„í†¨ë ˆë§ˆì´ì˜¤ìŠ¤ê°€ ì•Œë ‰ì‚°ë“œë¦¬ì•„ì˜ ê·¸ë¦¬ìŠ¤ ì‚¬íšŒ ì¼ì›ì´ë¼ëŠ” ê²ƒ ì™¸ì— ì‚¶ì˜ ì„¸ë°€í•œ ë¶€ë¶„ì€ ...</td>\n",
       "      <td>ì•Œë§ˆê²ŒìŠ¤íŠ¸</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  ë””ì‹œì¸ì‚¬ì´ë“œì—ì„œ ì¡°ì‚¬í•œ \"2008ë…„ ì˜¬í•´ ìµœê³ ì˜ ìœ í–‰ì–´ëŠ”?\"ì˜ ìˆœìœ„ì— ì˜¤ë¥¸ ë°œì–¸ì„ ...   \n",
       "1                  ì´ëª…ë°•ê³¼ ë°•ê·¼í˜œì˜ íšŒë™ì´ 11ê°œì›”ë§Œì— ì„±ì‚¬ëœ ë‚ ì€ ì–¸ì œì¸ê°€?   \n",
       "2                     í•´êµ¬ ë™ìª½ ì§€ì—­ì—ì„œëŠ” ì–´ë–¤ í˜•íƒœì˜ ì—¬ì§„ì´ ë°œìƒ ì¤‘ì¸ê°€?   \n",
       "3                     ë‚¨ìª½ íƒ‘ì— ì„¤ì¹˜ëœ ìŠ¤í˜ì‹œì˜¤ì‚¬ ì¢…ì˜ ë¬´ê²ŒëŠ” ëª‡ kgì¸ê°€?   \n",
       "4                                  ì²œë¬¸í•™ ì§‘ëŒ€ì„±ì˜ ì•„ëì–´ ì—­ë³¸ì€?   \n",
       "\n",
       "                                             context        answer  \\\n",
       "0  2008ë…„ 10ì›” êµ­íšŒì—ì„œ ì—´ë¦° êµ­ì •ê°ì‚¬ì—ì„œ ë¯¼ì£¼ë‹¹ ì´ì¢…ê±¸ ì˜ì›ì˜ ëŒ€í†µë ¹ì— ëŒ€í•œ ë¹„...           ìœ ì¸ì´Œ   \n",
       "1  2010ë…„ 8ì›” 22ì¼ ì´ëª…ë°•ê³¼ ë°•ê·¼í˜œì˜ íšŒë™ì´ 11ê°œì›”ë§Œì— ì„±ì‚¬ë˜ì—ˆë‹¤. 95ë¶„ë™ì•ˆ...  2010ë…„ 8ì›” 22ì¼   \n",
       "2  ë³¸ì§„ ì´í›„ ì¼ì–´ë‚˜ê³  ìˆëŠ” ì—¬ì§„ì€ ì´ì™€í…Œ í˜„ ì•ë°”ë‹¤ë¶€í„° ì´ë°”ë¼í‚¤ í˜„ ì•ë°”ë‹¤ê¹Œì§€ ë™ì„œ ...     í•´ì–‘ì§€ê° ë‚´ ì§€ì§„   \n",
       "3  1331ë…„ ì‹ ë‘ì˜ í† ëŒ€ê°€ ì„¤ì¹˜ë˜ì—ˆê³  2ë…„ í›„ì¸ 1333ë…„ì— í”„ë€ì²´ìŠ¤ì½” í˜íŠ¸ë¼ë¥´ì¹´ê°€ ...       5,200kg   \n",
       "4  í”„í†¨ë ˆë§ˆì´ì˜¤ìŠ¤ê°€ ì•Œë ‰ì‚°ë“œë¦¬ì•„ì˜ ê·¸ë¦¬ìŠ¤ ì‚¬íšŒ ì¼ì›ì´ë¼ëŠ” ê²ƒ ì™¸ì— ì‚¶ì˜ ì„¸ë°€í•œ ë¶€ë¶„ì€ ...         ì•Œë§ˆê²ŒìŠ¤íŠ¸   \n",
       "\n",
       "                                                text  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"] = df.apply(format_example, axis=1)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ë””ì‹œì¸ì‚¬ì´ë“œì—ì„œ ì¡°ì‚¬í•œ \"2008ë…„ ì˜¬í•´ ìµœê³ ì˜ ìœ í–‰ì–´ëŠ”?\"ì˜ ìˆœìœ„ì— ì˜¤ë¥¸ ë°œì–¸ì„ í•œ ì‚¬ëŒì€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2008ë…„ 10ì›” êµ­íšŒì—ì„œ ì—´ë¦° êµ­ì •ê°ì‚¬ì—ì„œ ë¯¼ì£¼ë‹¹ ì´ì¢…ê±¸ ì˜ì›ì˜ ëŒ€í†µë ¹ì— ëŒ€í•œ ë¹„ë‚œì— ëŒ€í•´ ì •íšŒ í›„ ë°˜ë°œí•˜ëŠ” ê³¼ì •ì—ì„œ ê¸°ìë“¤ì—ê²Œ ì†ê°€ë½ì§ˆì„ í•˜ë©° \"ì°ì§€ë§ˆ! XX ì°ì§€ë§ˆ. ì„±ì§ˆì´ ë»—ì³ì„œ ì •ë§\" ì´ë¼ëŠ” ìš•ì„¤ ë°œì–¸ì„ í•˜ì—¬ í¬ê²Œ ë¹„íŒì„ ë°›ì•˜ë‹¤. ë‹¹ì‹œ ìˆ˜ë§ì€ ê¸°ìë“¤ì´ ìˆëŠ” ìƒí™©ì—ì„œ ì´ ë°œì–¸ì´ ëª¨ë‘ ë…¹í™”ë˜ì—ˆìœ¼ë©° ë¯¼ì£¼ë‹¹ì„ ë¹„ë¡¯í•œ ì•¼ë‹¹ì€ ìœ  ì¥ê´€ì˜ ì´ëŸ° í–‰ìœ„ê°€ êµ­íšŒë¥¼ ëª¨ë…í•œ ê²ƒì´ë¼ë©° ë°˜ë“œì‹œ ì±…ì„ì„ ë¬»ê² ë‹¤ê³  ë§í•˜ì˜€ë‹¤. ìœ  ì¥ê´€ì€ í˜„ì¥ì—ì„œ ë°”ë¡œ ì‚¬ì§„ ê¸°ìë“¤ì—ê²Œ ì‚¬ê³¼ë¥¼ í•˜ê³  ìš•ì„¤ì´ ì•„ë‹ˆì—ˆë‹¤ê³  í•´ëª…ìë£Œë¥¼ ë°°í¬í–ˆìœ¼ë©°, ì´í‹€ í›„ ë‹¤ì‹œ ê³µì‹ ë¸Œë¦¬í•‘ì„ í†µí•´ ì‚¬ê³¼í–ˆë‹¤. ìœ ì¸ì´Œì´ êµ­ì •ê°ì‚¬ì¥ì—ì„œ í•œ ë°œì–¸ì€ 2008ë…„ì— ë””ì‹œì¸ì‚¬ì´ë“œì—ì„œ ì¡°ì‚¬í•œ \"2008ë…„ ì˜¬í•´ ìµœê³ ì˜ ìœ í–‰ì–´ëŠ”?\"ì˜ ìˆœìœ„ì— ì˜¤ë¥´ê¸°ë„ í•˜ì˜€ë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ìœ ì¸ì´Œ<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 s, sys: 0 ns, total: 39.5 s\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def count_tokens(row):\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False\n",
    "        )[\"input_ids\"]\n",
    "    )\n",
    "\n",
    "\n",
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(57139, 66181, 0.8633746845771445)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "plt.hist(df[\"token_count\"], ec=\"k\", bins=30, \n",
    "         weights=np.ones(len(df[\"token_count\"])) / len(df[\"token_count\"]))\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "len(df[df[\"token_count\"] < 512]), len(df), len(df[df['token_count'] < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "# í† í° ê¸¸ì´ë¡œ ì ë‹¹íˆ í•™ìŠµ ìƒ˜í”Œ ì„œë¸Œìƒ˜í”Œë§ \n",
    "df_sampled = df[df[\"token_count\"] < 512]\n",
    "df_sampled = df_sampled.sample(6000, random_state=SEED)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df_sampled, test_size=0.2, random_state=SEED)\n",
    "val, test = train_test_split(temp, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data ratio:0.8, 4800\n",
      "Valid data ratio:0.16, 960\n",
      "Test data ratio:0.04, 240\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data ratio:{len(train) / len(df_sampled)}, {len(train)}\")\n",
    "print(f\"Valid data ratio:{len(val) / len(df_sampled)}, {len(val)}\")\n",
    "print(f\"Test data ratio:{len(test) / len(df_sampled)}, {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=4000, random_state=SEED).to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=500, random_state=SEED).to_json(\"val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=100, random_state=SEED).to_json(\"test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\" : \"train.json\",\n",
    "        \"validation\" : \"val.json\",\n",
    "        \"test\" : \"test.json\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = f\"\"\"{data_row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{data_row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    ) # í”„ë¡¬í”„íŠ¸ ëì— <|start_header_id|>assistant<|end_header_id|> ë¥¼ ë¶™ì´ê²Œ ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_test_one_sample(example, model):\n",
    "    prompt = create_test_prompt(example)\n",
    "    print(\"\\nPROMPT\\n\", prompt.strip())\n",
    "\n",
    "    inputs = torch.tensor(\n",
    "        [tokenizer(prompt)[\"input_ids\"]]\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids = inputs,\n",
    "        max_new_tokens = 64,\n",
    "        use_cache = True,\n",
    "        temperature = 1.5,\n",
    "        min_p = 0.1\n",
    "    )\n",
    "\n",
    "    print(\"\\nANS\\n\", example[\"answer\"])\n",
    "    print(\"\\nPred\\n\", tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip())\n",
    "\n",
    "    return example['answer'], tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip()\n",
    "\n",
    "FastLanguageModel.for_inference(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ë² ë¦¬ê°€ ì‚¬ìš©í–ˆë˜ ê¸°íƒ€ëŠ” ë¬´ì—‡ì¸ê°€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1970ë…„ëŒ€ì˜ ë² ë¦¬ëŠ” ê·¸ì˜ ì´ˆê¸° ì„±ê³µì´ ë’·ë°›ì¹¨ë˜ì–´ íˆ¬ì–´ë¥¼ ì„±ì‚¬ì‹œì¼°ë‹¤. ê·¸ëŠ” ìˆ˜ë…„ê°„ ê¹ìŠ¨ ê¸°íƒ€ë¥¼ ì§Šì–´ì§€ê³  ì–´ë””ë¡œ ê°€ë“  ë°´ë“œê°€ ìì‹ ì˜ ìŒì•…ì„ ì•Œê³  ìˆì„ ê²ƒì´ë¼ê³  í™•ì‹ í•˜ë©´ì„œ ì´ë“¤ì„ ê³ ìš©í•˜ë©° ë¨¼ ê¸¸ì„ ë– ë‚¬ë‹¤. ì˜¬ë®¤ì§ì€ ì´ ì‹œê¸° ê·¸ì˜ \"ë¼ì´ë¸Œ ê³µì—°ì€ ê³„ì†í•´ì„œ ë¶ˆê·œì¹™í•´ì¡Œë‹¤ ... ë”ì°í•œ ë°±ì—… ë°´ë“œì™€ í˜‘ì—°í•˜ì—¬ ì„¤ë í•˜ë©°, ê°€ë½ ì•ˆ ë§ëŠ” ê³µì—°ì„ ë³´ì—¬ì¤¬ë‹¤.\"ë©´ì„œ ê·¸ì˜ ëª…ì„±ì— ë¨¹ì¹ ì„ í–ˆë‹¤ê³  í‰ë¡ í–ˆë‹¤. 1972ë…„ 3ì›”ì—ëŠ” ì‰í¼ë“œ ë¶€ì‹œì— ìœ„ì¹˜í•œ BBC í…”ë ˆë¹„ì „ ì‹œì–´í„°ì—ì„œ, ë°´ë“œ ë¼í‚¹ í˜¸ìŠ¤(Rocking Horse)ê°€ ë°±ì—…í•œ 60ì¼ì˜ íˆ¬ì–´ ì¤‘ ì¼ë¶€ì¸ ã€Šì²™ ë² ë¦¬ ì¸ ì½˜ì„œíŠ¸ã€‹ë¥¼ ìœ„í•´ ì˜í™”ë¥¼ ì°ëŠ”ë‹¤. 1970ë…„ëŒ€ ê·¸ì™€ í•¨ê»˜í•œ ìˆ˜ë§ì€ ë°±ì—… ë®¤ì§€ì…˜ ì¤‘ì—ì„œëŠ” ë§‰ ìŒì•…ì„ ì‹œì‘í•œ ë¸Œë£¨ìŠ¤ ìŠ¤í”„ë§ìŠ¤í‹´ê³¼ ìŠ¤í‹°ë¸Œ ë°€ëŸ¬ê°€ ìˆì—ˆë‹¤. ìŠ¤í”„ë§ìŠ¤í‹´ì€ ë‹¤íë©˜í„°ë¦¬ ì˜í™” ã€Ší—¤ì¼! í—¤ì¼! ë¡œí°ë¡¤ã€‹ì—ì„œ ë² ë¦¬ê°€ ë°´ë“œì—ê²Œ ì„¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì£¼ì§€ ì•Šì•˜ìœ¼ë©°, ê·¸ëŠ” ìì‹ ì˜ ê¸°íƒ€ ì¸íŠ¸ë¡œë¥¼ ë“£ê³  ê·¸ë“¤ì´ ì•Œì•„ì„œ ìì‹ ì—ê²Œ ë”°ë¼ì˜¬ ê²ƒì´ë¼ ê¸°ëŒ€í–ˆë‹¤ê³  ë§í–ˆë‹¤. ë² ë¦¬ëŠ” ê³µì—° ì´í›„ ë°´ë“œì—ê²Œ ê³ ë§™ë‹¤ëŠ” ì¸ì‚¬ í•˜ë‚˜ ì—†ì—ˆë‹¤. ê·¸ë ‡ì§€ë§Œ, ìŠ¤í”„ë§ìŠ¤í‹´ì€ ê·¸ê°€ 1995ë…„ì— ë¡œí°ë¡¤ ëª…ì˜ˆì˜ ì „ë‹¹ ì½˜ì„œíŠ¸ë¥¼ í•  ë•Œ ë² ë¦¬ì˜ ë°±ì—…ì„ ë‹¤ì‹œê¸ˆ ë§¡ì•„ì£¼ì—ˆë‹¤. ì§€ë¯¸ ì¹´í„°ì˜ ìš”ì²­ì— ì˜í•´ ë² ë¦¬ëŠ” 1979ë…„ 6ì›” 1ì¼ ë°±ì•…ê´€ì—ì„œ ê³µì—°í•˜ê¸°ë„ í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANS\n",
      " ê¹ìŠ¨ ê¸°íƒ€\n",
      "\n",
      "Pred\n",
      " ê·¸ì˜ ë°´ë“œì— ë°´ë“œ \"ë¡œí‚¹ í˜¸ìŠ¤(Rocking Horse)\"ì˜ ê°€Ã®të¡œ, 1972ë…„ 3ì›” BBC í…”ë ˆë¹„ì „ ì‹œì–´í„°ì—ì„œ, 1970ë…„ëŒ€ ê·¸ì™€ í•¨ê»˜í•œ ìˆ˜ë§ì€ ë°±ì—… ë®¤ì§€ì…˜ ì¤‘ì—ì„œë„, ë§‰\n"
     ]
    }
   ],
   "source": [
    "# Append\n",
    "untrained = []\n",
    "untrained.append(\n",
    "    int_test_one_sample(dataset[\"test\"][0], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì— ë°”ì´ì˜¤í•˜ìë“œ ì—„ë¸Œë ëŸ¬ í¬ë¡œë‹ˆí´ì¦ˆ í‹°ì € ì˜ìƒì´ ê³µê°œëœ ë‚ ì§œëŠ”?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2006ë…„ 11ì›” 3ì¼ì— ì—´ë¦° ë‹Œí…ë„ ì›”ë“œì—ì„œëŠ” 2007ë…„ì— ë°œë§¤ë  ì˜ˆì •ì´ë¼ëŠ” ë°œí‘œì™€ í•¨ê»˜ ê²Œì„ì˜ ì˜ìƒì´ ê³µê°œë˜ì—ˆë‹¤. 2007ë…„ 4ì›” 6ì¼ì—ëŠ” ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í‹°ì € ì˜ìƒì„ ê³µê°œí•˜ì˜€ë‹¤. ì´ì–´ì„œ 2007ë…„ 4ì›” 13ì¼ì—ëŠ” ìºë¦­í„° í”„ë¡œí•„ê³¼ ìŠ¤í¬ë¦°ìƒ·ì´ í¬í•¨ëœ ë‘ ë²ˆì§¸ íŠ¸ë ˆì¼ëŸ¬ê°€ ê³µê°œë˜ì—ˆë‹¤. ìº¡ì½¤ì˜ ê¸°íš ë° ì¡°ì‚¬ ë””ë ‰í„° í¬ë¦¬ìŠ¤í‹°ì•ˆ ìŠ¤ë²¤ìŠ¨ì€ ê²Œì„ì´ 480ì˜ ìˆœì°¨ ì£¼ì‚¬ ë°©ì‹ê³¼ 16:9ì˜ ì™€ì´ë“œìŠ¤í¬ë¦°ì„ ì§€ì›í•  ê²ƒì´ë¼ê³  ì–¸ê¸‰í•˜ì˜€ë‹¤. ã€Šë°”ì´ì˜¤í•˜ìë“œ 4 ìœ„ ì—ë””ì…˜ã€‹ì—ë„ íŠ¹ì „ ì˜ìƒìœ¼ë¡œ íŠ¸ë ˆì¼ëŸ¬ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ë°, ì—¬ê¸°ì— í¬í•¨ëœ ì˜ìƒì€ ì˜¤ë¦¬ì§€ë„ì˜ ì–‘ê´€ê³¼ ë¼ì¿¤ ì‹œì˜ ì¼ë¶€ ì§€ì—­ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. 2007ë…„ 7ì›” 11ì¼ì˜ E3ì—ì„œ ë‹Œí…ë„ ì¸¡ì€ ì´ ì•…ì„¸ì‚¬ë¦¬ì¸ Wii ì¬í¼ë¥¼ ê²Œì„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ê³  ì–¸ê¸‰í•˜ì˜€ë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 2007ë…„ 4ì›” 6ì¼\n",
      "\n",
      "Pred\n",
      " 2007ë…„ 4ì›” 6ì¼ ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ TIzer ì˜ìƒì„ ê³µê°œí•˜ì˜€ë‹¤.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    int_test_one_sample(dataset['test'][1], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "í°í‹°ì•¡ì „ìŸì„ í•™ì‚´ì˜ ê´‘ê¸°ë¡œ ë¬˜ì‚¬í•œ ì‚¬í•™ìëŠ”?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ì˜êµ­ ì •ì°©ë¯¼ê³¼ ì¸ë””ì–¸ê³¼ì˜ ê´€ê³„ëŠ”, í”„ë Œì¹˜ ì¸ë””ì–¸ ì „ìŸ ë•Œ ê·¹ë„ì˜ ê¸´ì¥ ê´€ê³„ì— ìˆì—ˆì§€ë§Œ, í°í‹°ì•¡ ì „ìŸ ë™ì•ˆì— ì˜¤íˆë ¤ ì™„í™”ëë‹¤. ì‚¬í•™ì ë°ì´ë¹„ë“œ ë”•ìŠ¨ì€ â€œí°í‹°ì•¡ ì „ìŸì€ ì–‘ì¸¡ ëª¨ë‘ í•™ì‚´ì˜ ê´‘ê¸°ì— ì·¨í•´ ë²„ë¦° ë“¯, ê·¸ ë¬´ì„œìš´ í­ë ¥ì´ ì „ë¡€ê°€ ì—†ë˜ ê²ƒì´ì—ˆë‹¤.â€ê³  í‰ê°€í–ˆë‹¤. ì‚¬í•™ì ë‹¤ë‹ˆì—˜ ë¦¬íˆí„°ëŠ” ì¸ë””ì–¸ì´ ì˜êµ­êµ°ì„ ëª°ì•„ë‚´ë ¤ëŠ” í•œ ê²ƒê³¼ íŒ©ìŠ¤í„´ ë³´ì´ì¦ˆê°€ ë°±ì¸ ì‚¬íšŒì—ì„œ ì¸ë””ì–¸ì„ ì—†ì• ë ¤ê³  í•œ ê²ƒì„ ì¸ì¢… ì²­ì†Œì˜ ì˜ˆë¼ê³  ìƒê°í–ˆë‹¤. ì „ìŸì— ê´€ë ¨ëœ ì–‘ì¸¡ ëª¨ë‘ ì •ì°©ë¯¼ê³¼ ì›ì£¼ë¯¼ì€ ë³¸ì§ˆì ìœ¼ë¡œ ë‹¤ë¥´ë©°, ê³µìƒí•  ìˆ˜ ì—†ë‹¤ëŠ” ê²°ë¡ ì— ë„ë‹¬í–ˆë‹¤. ë¦¬íˆí„°ëŠ” ì´ ì „ìŸì´ â€œëª¨ë“  ì›ì£¼ë¯¼ì€ â€˜ì¸ë””ì–¸â€™ì´ê³  ê° ìœ ëŸ½ê³„ ë¯¸êµ­ì¸ì€ â€˜ë°±ì¸â€™ì´ë©°, í•œìª½ì€ ë‹¤ë¥¸ í•œìª½ì„ íŒŒê´´í•˜ê¸° ìœ„í•´ ê²°ì†í•˜ëŠ” ìƒˆë¡œìš´ ì‚¬ê³ ë°©ì‹ì„ ê°€ì ¸ ì˜¤ê²Œ ë˜ì—ˆë‹¤.â€ê³  í‰í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ë°ì´ë¹„ë“œ ë”•ìŠ¨\n",
      "\n",
      "Pred\n",
      " ë‹¤ë‹ˆì—˜ ë¦¬íˆí„°<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    int_test_one_sample(dataset['test'][2], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì¿ ë¹Œë¼ì´ì™€ ë™ë§¹ì„ ë§ºê³ ë‚˜ì„œ ì¹´ì´ë‘ê°€ ì•„ë¦¬í¬ ë¶€ì¼€ë¥¼ ë„ì™”ë‹¤ëŠ” êµ¬ì‹¤ë¡œ ì¹´ì´ë‘ë¥¼ ê³µê²©í•œ ì¸ë¬¼ì€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1259ë…„, ëª½ì¼€ ì¹¸ì´ ë‚¨ì†¡ ì›ì • ì¤‘ ì‚¬ë§í•˜ì ë‹¤ìŒ í•´ì¸ 1260ë…„ì— ê·¸ì˜ ë™ìƒì¸ ì¿ ë¹Œë¼ì´ì™€ ì•„ë¦¬í¬ ë¶€ì¼€ê°€ ê°ê° ëŒ€ì¹¸ì„ ì¹­í–ˆë‹¤. ì„œë¡œ ëŒ€ì¹¸ì„ ì¹­í•œ ì¿ ë¹Œë¼ì´ì™€ ì•„ë¦¬í¬ ë¶€ì¼€ëŠ” ê³§ë°”ë¡œ ì „ìŸì— ë“¤ì–´ê°”ë‹¤. ì „ìŸì€ ì¤‘êµ­ ë¶ë¶€ì˜ í’ë¶€í•œ ë¬¼ìë¥¼ ê°€ì§„ ì¿ ë¹Œë¼ì´ì—ê²Œ ì‹œì¢…ì¼ê´€ ìœ ë¦¬í•˜ê²Œ ì§„í–‰ëë‹¤. ì´ì— ì•„ë¦¬í¬ ë¶€ì¼€ëŠ” ìì‹ ì´ ì„ëª…í•œ ì°¨ê°€íƒ€ì´ ì¹¸êµ­ì˜ ì•Œë£¨êµ¬ì—ê²Œ ë„ì›€ì„ ìš”ì²­í–ˆì§€ë§Œ ì•Œë£¨êµ¬ëŠ” ì´ ìš”ì²­ì„ ê±°ì ˆí•˜ê³  ì˜¤íˆë ¤ 1263ë…„ì— ì¿ ë¹Œë¼ì´ì™€ ë™ë§¹ì„ ë§ºì—ˆë‹¤. ì¿ ë¹Œë¼ì´ì™€ ë™ë§¹ì„ ë§ºì€ ì•Œë£¨êµ¬ëŠ” ì¹´ì´ë‘ê°€ ì•„ë¦¬í¬ ë¶€ì¼€ë¥¼ ë„ì™”ë‹¤ëŠ” êµ¬ì‹¤ë¡œ ì¹´ì´ë‘ë¥¼ ê³µê²©í–ˆë‹¤. ì•Œë£¨êµ¬ì˜ ê³µê²©ì„ ë°›ì€ ì¹´ì´ë‘ëŠ” í‚µì°¨í¬ ì¹¸êµ­ì˜ ë² ë¥´ì¼€ì˜ ì§€ì›ì„ ë°›ì•„ ì°¨ê°€íƒ€ì´ ì¹¸êµ­ì˜ ì˜í† ë¡œ ì¹¨ì…í•˜ì—¬ ì•Œë£¨êµ¬ì™€ì˜ ì „íˆ¬ì—ì„œ ìŠ¹ë¦¬ë¥¼ ê±°ë‘ì—ˆìœ¼ë‚˜ ë‹¤ìŒ ë²ˆ ì „íˆ¬ì—ì„œ ë°˜ê²©ì„ ë‹¹í•´ ë³¸êµ­ìœ¼ë¡œ ì² ìˆ˜í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ì•Œë£¨êµ¬\n",
      "\n",
      "Pred\n",
      " ì•Œë£¨êµ¬<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    int_test_one_sample(dataset['test'][3], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ê¹ìŠ¨ ê¸°íƒ€',\n",
       "  'ê·¸ì˜ ë°´ë“œì— ë°´ë“œ \"ë¡œí‚¹ í˜¸ìŠ¤(Rocking Horse)\"ì˜ ê°€Ã®të¡œ, 1972ë…„ 3ì›” BBC í…”ë ˆë¹„ì „ ì‹œì–´í„°ì—ì„œ, 1970ë…„ëŒ€ ê·¸ì™€ í•¨ê»˜í•œ ìˆ˜ë§ì€ ë°±ì—… ë®¤ì§€ì…˜ ì¤‘ì—ì„œë„, ë§‰'),\n",
       " ('2007ë…„ 4ì›” 6ì¼', '2007ë…„ 4ì›” 6ì¼ ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ TIzer ì˜ìƒì„ ê³µê°œí•˜ì˜€ë‹¤.<|eot_id|>'),\n",
       " ('ë°ì´ë¹„ë“œ ë”•ìŠ¨', 'ë‹¤ë‹ˆì—˜ ë¦¬íˆí„°<|eot_id|>'),\n",
       " ('ì•Œë£¨êµ¬', 'ì•Œë£¨êµ¬<|eot_id|>')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(lora_model);\n",
    "FastLanguageModel.for_training(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [00:00<00:00, 7732.57 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 7637.00 examples/s]\n",
      "/home/mgyukim/.conda/envs/llama/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [00:00<00:00, 5524.35 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 5363.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = lora_model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"validation\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 1,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.2,\n",
    "        save_steps=0.2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 4,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 08:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.238357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.192190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.182273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.233200</td>\n",
       "      <td>0.170069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.165058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained = []\n",
    "FastLanguageModel.for_inference(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ë² ë¦¬ê°€ ì‚¬ìš©í–ˆë˜ ê¸°íƒ€ëŠ” ë¬´ì—‡ì¸ê°€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1970ë…„ëŒ€ì˜ ë² ë¦¬ëŠ” ê·¸ì˜ ì´ˆê¸° ì„±ê³µì´ ë’·ë°›ì¹¨ë˜ì–´ íˆ¬ì–´ë¥¼ ì„±ì‚¬ì‹œì¼°ë‹¤. ê·¸ëŠ” ìˆ˜ë…„ê°„ ê¹ìŠ¨ ê¸°íƒ€ë¥¼ ì§Šì–´ì§€ê³  ì–´ë””ë¡œ ê°€ë“  ë°´ë“œê°€ ìì‹ ì˜ ìŒì•…ì„ ì•Œê³  ìˆì„ ê²ƒì´ë¼ê³  í™•ì‹ í•˜ë©´ì„œ ì´ë“¤ì„ ê³ ìš©í•˜ë©° ë¨¼ ê¸¸ì„ ë– ë‚¬ë‹¤. ì˜¬ë®¤ì§ì€ ì´ ì‹œê¸° ê·¸ì˜ \"ë¼ì´ë¸Œ ê³µì—°ì€ ê³„ì†í•´ì„œ ë¶ˆê·œì¹™í•´ì¡Œë‹¤ ... ë”ì°í•œ ë°±ì—… ë°´ë“œì™€ í˜‘ì—°í•˜ì—¬ ì„¤ë í•˜ë©°, ê°€ë½ ì•ˆ ë§ëŠ” ê³µì—°ì„ ë³´ì—¬ì¤¬ë‹¤.\"ë©´ì„œ ê·¸ì˜ ëª…ì„±ì— ë¨¹ì¹ ì„ í–ˆë‹¤ê³  í‰ë¡ í–ˆë‹¤. 1972ë…„ 3ì›”ì—ëŠ” ì‰í¼ë“œ ë¶€ì‹œì— ìœ„ì¹˜í•œ BBC í…”ë ˆë¹„ì „ ì‹œì–´í„°ì—ì„œ, ë°´ë“œ ë¼í‚¹ í˜¸ìŠ¤(Rocking Horse)ê°€ ë°±ì—…í•œ 60ì¼ì˜ íˆ¬ì–´ ì¤‘ ì¼ë¶€ì¸ ã€Šì²™ ë² ë¦¬ ì¸ ì½˜ì„œíŠ¸ã€‹ë¥¼ ìœ„í•´ ì˜í™”ë¥¼ ì°ëŠ”ë‹¤. 1970ë…„ëŒ€ ê·¸ì™€ í•¨ê»˜í•œ ìˆ˜ë§ì€ ë°±ì—… ë®¤ì§€ì…˜ ì¤‘ì—ì„œëŠ” ë§‰ ìŒì•…ì„ ì‹œì‘í•œ ë¸Œë£¨ìŠ¤ ìŠ¤í”„ë§ìŠ¤í‹´ê³¼ ìŠ¤í‹°ë¸Œ ë°€ëŸ¬ê°€ ìˆì—ˆë‹¤. ìŠ¤í”„ë§ìŠ¤í‹´ì€ ë‹¤íë©˜í„°ë¦¬ ì˜í™” ã€Ší—¤ì¼! í—¤ì¼! ë¡œí°ë¡¤ã€‹ì—ì„œ ë² ë¦¬ê°€ ë°´ë“œì—ê²Œ ì„¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì£¼ì§€ ì•Šì•˜ìœ¼ë©°, ê·¸ëŠ” ìì‹ ì˜ ê¸°íƒ€ ì¸íŠ¸ë¡œë¥¼ ë“£ê³  ê·¸ë“¤ì´ ì•Œì•„ì„œ ìì‹ ì—ê²Œ ë”°ë¼ì˜¬ ê²ƒì´ë¼ ê¸°ëŒ€í–ˆë‹¤ê³  ë§í–ˆë‹¤. ë² ë¦¬ëŠ” ê³µì—° ì´í›„ ë°´ë“œì—ê²Œ ê³ ë§™ë‹¤ëŠ” ì¸ì‚¬ í•˜ë‚˜ ì—†ì—ˆë‹¤. ê·¸ë ‡ì§€ë§Œ, ìŠ¤í”„ë§ìŠ¤í‹´ì€ ê·¸ê°€ 1995ë…„ì— ë¡œí°ë¡¤ ëª…ì˜ˆì˜ ì „ë‹¹ ì½˜ì„œíŠ¸ë¥¼ í•  ë•Œ ë² ë¦¬ì˜ ë°±ì—…ì„ ë‹¤ì‹œê¸ˆ ë§¡ì•„ì£¼ì—ˆë‹¤. ì§€ë¯¸ ì¹´í„°ì˜ ìš”ì²­ì— ì˜í•´ ë² ë¦¬ëŠ” 1979ë…„ 6ì›” 1ì¼ ë°±ì•…ê´€ì—ì„œ ê³µì—°í•˜ê¸°ë„ í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ê¹ìŠ¨ ê¸°íƒ€\n",
      "\n",
      "Pred\n",
      " ê¹ìŠ¨<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][0], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì— ë°”ì´ì˜¤í•˜ìë“œ ì—„ë¸Œë ëŸ¬ í¬ë¡œë‹ˆí´ì¦ˆ í‹°ì € ì˜ìƒì´ ê³µê°œëœ ë‚ ì§œëŠ”?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2006ë…„ 11ì›” 3ì¼ì— ì—´ë¦° ë‹Œí…ë„ ì›”ë“œì—ì„œëŠ” 2007ë…„ì— ë°œë§¤ë  ì˜ˆì •ì´ë¼ëŠ” ë°œí‘œì™€ í•¨ê»˜ ê²Œì„ì˜ ì˜ìƒì´ ê³µê°œë˜ì—ˆë‹¤. 2007ë…„ 4ì›” 6ì¼ì—ëŠ” ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í‹°ì € ì˜ìƒì„ ê³µê°œí•˜ì˜€ë‹¤. ì´ì–´ì„œ 2007ë…„ 4ì›” 13ì¼ì—ëŠ” ìºë¦­í„° í”„ë¡œí•„ê³¼ ìŠ¤í¬ë¦°ìƒ·ì´ í¬í•¨ëœ ë‘ ë²ˆì§¸ íŠ¸ë ˆì¼ëŸ¬ê°€ ê³µê°œë˜ì—ˆë‹¤. ìº¡ì½¤ì˜ ê¸°íš ë° ì¡°ì‚¬ ë””ë ‰í„° í¬ë¦¬ìŠ¤í‹°ì•ˆ ìŠ¤ë²¤ìŠ¨ì€ ê²Œì„ì´ 480ì˜ ìˆœì°¨ ì£¼ì‚¬ ë°©ì‹ê³¼ 16:9ì˜ ì™€ì´ë“œìŠ¤í¬ë¦°ì„ ì§€ì›í•  ê²ƒì´ë¼ê³  ì–¸ê¸‰í•˜ì˜€ë‹¤. ã€Šë°”ì´ì˜¤í•˜ìë“œ 4 ìœ„ ì—ë””ì…˜ã€‹ì—ë„ íŠ¹ì „ ì˜ìƒìœ¼ë¡œ íŠ¸ë ˆì¼ëŸ¬ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ë°, ì—¬ê¸°ì— í¬í•¨ëœ ì˜ìƒì€ ì˜¤ë¦¬ì§€ë„ì˜ ì–‘ê´€ê³¼ ë¼ì¿¤ ì‹œì˜ ì¼ë¶€ ì§€ì—­ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. 2007ë…„ 7ì›” 11ì¼ì˜ E3ì—ì„œ ë‹Œí…ë„ ì¸¡ì€ ì´ ì•…ì„¸ì‚¬ë¦¬ì¸ Wii ì¬í¼ë¥¼ ê²Œì„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ê³  ì–¸ê¸‰í•˜ì˜€ë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 2007ë…„ 4ì›” 6ì¼\n",
      "\n",
      "Pred\n",
      " 2007ë…„ 4ì›” 6ì¼<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][1], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "í°í‹°ì•¡ì „ìŸì„ í•™ì‚´ì˜ ê´‘ê¸°ë¡œ ë¬˜ì‚¬í•œ ì‚¬í•™ìëŠ”?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ì˜êµ­ ì •ì°©ë¯¼ê³¼ ì¸ë””ì–¸ê³¼ì˜ ê´€ê³„ëŠ”, í”„ë Œì¹˜ ì¸ë””ì–¸ ì „ìŸ ë•Œ ê·¹ë„ì˜ ê¸´ì¥ ê´€ê³„ì— ìˆì—ˆì§€ë§Œ, í°í‹°ì•¡ ì „ìŸ ë™ì•ˆì— ì˜¤íˆë ¤ ì™„í™”ëë‹¤. ì‚¬í•™ì ë°ì´ë¹„ë“œ ë”•ìŠ¨ì€ â€œí°í‹°ì•¡ ì „ìŸì€ ì–‘ì¸¡ ëª¨ë‘ í•™ì‚´ì˜ ê´‘ê¸°ì— ì·¨í•´ ë²„ë¦° ë“¯, ê·¸ ë¬´ì„œìš´ í­ë ¥ì´ ì „ë¡€ê°€ ì—†ë˜ ê²ƒì´ì—ˆë‹¤.â€ê³  í‰ê°€í–ˆë‹¤. ì‚¬í•™ì ë‹¤ë‹ˆì—˜ ë¦¬íˆí„°ëŠ” ì¸ë””ì–¸ì´ ì˜êµ­êµ°ì„ ëª°ì•„ë‚´ë ¤ëŠ” í•œ ê²ƒê³¼ íŒ©ìŠ¤í„´ ë³´ì´ì¦ˆê°€ ë°±ì¸ ì‚¬íšŒì—ì„œ ì¸ë””ì–¸ì„ ì—†ì• ë ¤ê³  í•œ ê²ƒì„ ì¸ì¢… ì²­ì†Œì˜ ì˜ˆë¼ê³  ìƒê°í–ˆë‹¤. ì „ìŸì— ê´€ë ¨ëœ ì–‘ì¸¡ ëª¨ë‘ ì •ì°©ë¯¼ê³¼ ì›ì£¼ë¯¼ì€ ë³¸ì§ˆì ìœ¼ë¡œ ë‹¤ë¥´ë©°, ê³µìƒí•  ìˆ˜ ì—†ë‹¤ëŠ” ê²°ë¡ ì— ë„ë‹¬í–ˆë‹¤. ë¦¬íˆí„°ëŠ” ì´ ì „ìŸì´ â€œëª¨ë“  ì›ì£¼ë¯¼ì€ â€˜ì¸ë””ì–¸â€™ì´ê³  ê° ìœ ëŸ½ê³„ ë¯¸êµ­ì¸ì€ â€˜ë°±ì¸â€™ì´ë©°, í•œìª½ì€ ë‹¤ë¥¸ í•œìª½ì„ íŒŒê´´í•˜ê¸° ìœ„í•´ ê²°ì†í•˜ëŠ” ìƒˆë¡œìš´ ì‚¬ê³ ë°©ì‹ì„ ê°€ì ¸ ì˜¤ê²Œ ë˜ì—ˆë‹¤.â€ê³  í‰í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ë°ì´ë¹„ë“œ ë”•ìŠ¨\n",
      "\n",
      "Pred\n",
      " ë°ì´ë¹„ë“œ ë”•ìŠ¨<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][2], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì¿ ë¹Œë¼ì´ì™€ ë™ë§¹ì„ ë§ºê³ ë‚˜ì„œ ì¹´ì´ë‘ê°€ ì•„ë¦¬í¬ ë¶€ì¼€ë¥¼ ë„ì™”ë‹¤ëŠ” êµ¬ì‹¤ë¡œ ì¹´ì´ë‘ë¥¼ ê³µê²©í•œ ì¸ë¬¼ì€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "1259ë…„, ëª½ì¼€ ì¹¸ì´ ë‚¨ì†¡ ì›ì • ì¤‘ ì‚¬ë§í•˜ì ë‹¤ìŒ í•´ì¸ 1260ë…„ì— ê·¸ì˜ ë™ìƒì¸ ì¿ ë¹Œë¼ì´ì™€ ì•„ë¦¬í¬ ë¶€ì¼€ê°€ ê°ê° ëŒ€ì¹¸ì„ ì¹­í–ˆë‹¤. ì„œë¡œ ëŒ€ì¹¸ì„ ì¹­í•œ ì¿ ë¹Œë¼ì´ì™€ ì•„ë¦¬í¬ ë¶€ì¼€ëŠ” ê³§ë°”ë¡œ ì „ìŸì— ë“¤ì–´ê°”ë‹¤. ì „ìŸì€ ì¤‘êµ­ ë¶ë¶€ì˜ í’ë¶€í•œ ë¬¼ìë¥¼ ê°€ì§„ ì¿ ë¹Œë¼ì´ì—ê²Œ ì‹œì¢…ì¼ê´€ ìœ ë¦¬í•˜ê²Œ ì§„í–‰ëë‹¤. ì´ì— ì•„ë¦¬í¬ ë¶€ì¼€ëŠ” ìì‹ ì´ ì„ëª…í•œ ì°¨ê°€íƒ€ì´ ì¹¸êµ­ì˜ ì•Œë£¨êµ¬ì—ê²Œ ë„ì›€ì„ ìš”ì²­í–ˆì§€ë§Œ ì•Œë£¨êµ¬ëŠ” ì´ ìš”ì²­ì„ ê±°ì ˆí•˜ê³  ì˜¤íˆë ¤ 1263ë…„ì— ì¿ ë¹Œë¼ì´ì™€ ë™ë§¹ì„ ë§ºì—ˆë‹¤. ì¿ ë¹Œë¼ì´ì™€ ë™ë§¹ì„ ë§ºì€ ì•Œë£¨êµ¬ëŠ” ì¹´ì´ë‘ê°€ ì•„ë¦¬í¬ ë¶€ì¼€ë¥¼ ë„ì™”ë‹¤ëŠ” êµ¬ì‹¤ë¡œ ì¹´ì´ë‘ë¥¼ ê³µê²©í–ˆë‹¤. ì•Œë£¨êµ¬ì˜ ê³µê²©ì„ ë°›ì€ ì¹´ì´ë‘ëŠ” í‚µì°¨í¬ ì¹¸êµ­ì˜ ë² ë¥´ì¼€ì˜ ì§€ì›ì„ ë°›ì•„ ì°¨ê°€íƒ€ì´ ì¹¸êµ­ì˜ ì˜í† ë¡œ ì¹¨ì…í•˜ì—¬ ì•Œë£¨êµ¬ì™€ì˜ ì „íˆ¬ì—ì„œ ìŠ¹ë¦¬ë¥¼ ê±°ë‘ì—ˆìœ¼ë‚˜ ë‹¤ìŒ ë²ˆ ì „íˆ¬ì—ì„œ ë°˜ê²©ì„ ë‹¹í•´ ë³¸êµ­ìœ¼ë¡œ ì² ìˆ˜í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ì•Œë£¨êµ¬\n",
      "\n",
      "Pred\n",
      " ì•Œë£¨êµ¬<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    int_test_one_sample(dataset['test'][3], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì •ë‹µ</th>\n",
       "      <th>í•™ìŠµì „ ì¶œë ¥</th>\n",
       "      <th>í•™ìŠµí›„ ì¶œë ¥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ê¹ìŠ¨ ê¸°íƒ€</td>\n",
       "      <td>ê·¸ì˜ ë°´ë“œì— ë°´ë“œ \"ë¡œí‚¹ í˜¸ìŠ¤(Rocking Horse)\"ì˜ ê°€Ã®të¡œ, 1972ë…„ ...</td>\n",
       "      <td>ê¹ìŠ¨&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007ë…„ 4ì›” 6ì¼</td>\n",
       "      <td>2007ë…„ 4ì›” 6ì¼ ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ TIzer ì˜ìƒì„ ê³µê°œí•˜ì˜€ë‹¤.&lt;|eo...</td>\n",
       "      <td>2007ë…„ 4ì›” 6ì¼&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë°ì´ë¹„ë“œ ë”•ìŠ¨</td>\n",
       "      <td>ë‹¤ë‹ˆì—˜ ë¦¬íˆí„°&lt;|eot_id|&gt;</td>\n",
       "      <td>ë°ì´ë¹„ë“œ ë”•ìŠ¨&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì•Œë£¨êµ¬</td>\n",
       "      <td>ì•Œë£¨êµ¬&lt;|eot_id|&gt;</td>\n",
       "      <td>ì•Œë£¨êµ¬&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ì •ë‹µ                                             í•™ìŠµì „ ì¶œë ¥  \\\n",
       "0        ê¹ìŠ¨ ê¸°íƒ€  ê·¸ì˜ ë°´ë“œì— ë°´ë“œ \"ë¡œí‚¹ í˜¸ìŠ¤(Rocking Horse)\"ì˜ ê°€Ã®të¡œ, 1972ë…„ ...   \n",
       "1  2007ë…„ 4ì›” 6ì¼  2007ë…„ 4ì›” 6ì¼ ì¼ë³¸ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ TIzer ì˜ìƒì„ ê³µê°œí•˜ì˜€ë‹¤.<|eo...   \n",
       "2      ë°ì´ë¹„ë“œ ë”•ìŠ¨                                  ë‹¤ë‹ˆì—˜ ë¦¬íˆí„°<|eot_id|>   \n",
       "3          ì•Œë£¨êµ¬                                      ì•Œë£¨êµ¬<|eot_id|>   \n",
       "\n",
       "                  í•™ìŠµí›„ ì¶œë ¥  \n",
       "0           ê¹ìŠ¨<|eot_id|>  \n",
       "1  2007ë…„ 4ì›” 6ì¼<|eot_id|>  \n",
       "2      ë°ì´ë¹„ë“œ ë”•ìŠ¨<|eot_id|>  \n",
       "3          ì•Œë£¨êµ¬<|eot_id|>  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[(utrd[0], utrd[1], trd[1]) for utrd, trd in zip(untrained, trained)],\n",
    "    columns=['ì •ë‹µ', 'í•™ìŠµì „ ì¶œë ¥', 'í•™ìŠµí›„ ì¶œë ¥']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
