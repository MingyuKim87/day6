{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_train.json -O KorQuAD_v1.0_train.json\n",
    "# !wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_dev.json -O KorQuAD_v1.0_dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"]=\"1\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./KorQuAD_v1.0_dev.json', 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open('./KorQuAD_v1.0_train.json', 'r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def korquad_to_dataframe(data):\n",
    "    rows = []\n",
    "    for paragraph in data['data']:\n",
    "        paragraph_title = paragraph['title']\n",
    "\n",
    "        for qa in paragraph['paragraphs']:\n",
    "            context = qa['context']\n",
    "\n",
    "            for question in qa['qas']:\n",
    "                q = question['question']\n",
    "                qa_id = question['id']\n",
    "\n",
    "                for answer in question['answers']:\n",
    "                    a = answer['text']\n",
    "                    rows.append({\n",
    "                        'question': q,\n",
    "                        'answer': a,\n",
    "                        'qa_id': qa_id,\n",
    "                        'context': context,\n",
    "                        'paragraph_title': paragraph_title\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>명예의 전당에 들어가려면 은퇴 후 몇년이 지나야 하는가?</td>\n",
       "      <td>5년</td>\n",
       "      <td>6469691-2-1</td>\n",
       "      <td>300 승은 야구 명예의 전당에 들어갈 수 있는 보증 수표처럼 여겨지는데, 이 투수...</td>\n",
       "      <td>300_승_클럽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>윤상이 나레이션을 맡은 EBS 다큐프라임 제목은 무엇인가?</td>\n",
       "      <td>한국의 강</td>\n",
       "      <td>5835201-5-2</td>\n",
       "      <td>2010년 3월에는 뉴욕에서 대학원을 졸업하고 유학 생활을 정리한 뒤 귀국하여 상명...</td>\n",
       "      <td>윤상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안전기술의 원전 확장을 위해 개발되는 것은?</td>\n",
       "      <td>상용경수로</td>\n",
       "      <td>6588949-2-1</td>\n",
       "      <td>미래전략기술 개발을 위해서 먼저 신기술 융합·접목을 통한 새로운 원자력 영역 개척이...</td>\n",
       "      <td>원자력진흥종합계획</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이명박이 군대 입대 후 훈련소에서 강제 퇴소 당한 이유는?</td>\n",
       "      <td>기관지확장증</td>\n",
       "      <td>6545197-0-0</td>\n",
       "      <td>이태원시장에서 매일 새벽 청소 일을 하는 환경미화원으로 학업을 이어가던 중 생활고를...</td>\n",
       "      <td>이명박</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970년 네덜란드 그랑프리에서 사망한 선수는?</td>\n",
       "      <td>피어스 커리지</td>\n",
       "      <td>6464976-3-0</td>\n",
       "      <td>하지만 언제나 순조롭지만은 않았다. 1970년 피어스 커리지(Piers Courag...</td>\n",
       "      <td>뉘르부르크링</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question   answer        qa_id  \\\n",
       "0    명예의 전당에 들어가려면 은퇴 후 몇년이 지나야 하는가?       5년  6469691-2-1   \n",
       "1  윤상이 나레이션을 맡은 EBS 다큐프라임 제목은 무엇인가?     한국의 강  5835201-5-2   \n",
       "2           안전기술의 원전 확장을 위해 개발되는 것은?    상용경수로  6588949-2-1   \n",
       "3   이명박이 군대 입대 후 훈련소에서 강제 퇴소 당한 이유는?   기관지확장증  6545197-0-0   \n",
       "4         1970년 네덜란드 그랑프리에서 사망한 선수는?  피어스 커리지  6464976-3-0   \n",
       "\n",
       "                                             context paragraph_title  \n",
       "0  300 승은 야구 명예의 전당에 들어갈 수 있는 보증 수표처럼 여겨지는데, 이 투수...        300_승_클럽  \n",
       "1  2010년 3월에는 뉴욕에서 대학원을 졸업하고 유학 생활을 정리한 뒤 귀국하여 상명...              윤상  \n",
       "2  미래전략기술 개발을 위해서 먼저 신기술 융합·접목을 통한 새로운 원자력 영역 개척이...       원자력진흥종합계획  \n",
       "3  이태원시장에서 매일 새벽 청소 일을 하는 환경미화원으로 학업을 이어가던 중 생활고를...             이명박  \n",
       "4  하지만 언제나 순조롭지만은 않았다. 1970년 피어스 커리지(Piers Courag...          뉘르부르크링  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = korquad_to_dataframe(dev_data)\n",
    "df_dev = df_dev.sample(frac=1).reset_index(drop=True)\n",
    "print(df_dev.shape)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60407, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilberg은 유대인 박해를 통해 설명할 수 있는 유대인들의 성향을 무엇이라고 했는가?</td>\n",
       "      <td>순응적인 태도</td>\n",
       "      <td>6571960-23-1</td>\n",
       "      <td>Peter Longerich 역시 막대한 연구 끝에 “유대인들은 실질적으로 어떠한 ...</td>\n",
       "      <td>홀로코스트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>야금 연구소가 중성자 감속재로 사용한 것은?</td>\n",
       "      <td>흑연</td>\n",
       "      <td>6502200-4-0</td>\n",
       "      <td>한편, 핵반응 기술에 대한 연구 역시 두 가지로 나뉘었다. 컬럼비아 대학교의 해럴드...</td>\n",
       "      <td>맨해튼_계획</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007년 8월 15일 아유가 프로리그 데뷔전을 치룰 때 누구와 교체되어 경기에 투...</td>\n",
       "      <td>모드스트 음바미</td>\n",
       "      <td>6539928-1-0</td>\n",
       "      <td>2007년 8월 15일 발랑시엔전에서 모드스트 음바미와 89분에 교체되어 프로리그 ...</td>\n",
       "      <td>앙드레_아유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>베일이 아스널과 경기했던 때는?</td>\n",
       "      <td>2010년 4월</td>\n",
       "      <td>6473562-3-1</td>\n",
       "      <td>베일은 인상적인 활약을 계속해 나가며 풀럼과의 FA컵 6라운드 재경기에서 3-1 승...</td>\n",
       "      <td>가레스_베일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>맨체스터 시티가 2009-10 시즌 개막전에서 이긴 팀은?</td>\n",
       "      <td>블랙번 로버스</td>\n",
       "      <td>6529318-14-1</td>\n",
       "      <td>맨체스터 시티는 그 시즌 결국 리그 10위로 마감하였고 휴스는 팀을 더욱더 강화시키...</td>\n",
       "      <td>맨체스터_시티_FC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question    answer         qa_id  \\\n",
       "0  Hilberg은 유대인 박해를 통해 설명할 수 있는 유대인들의 성향을 무엇이라고 했는가?   순응적인 태도  6571960-23-1   \n",
       "1                           야금 연구소가 중성자 감속재로 사용한 것은?        흑연   6502200-4-0   \n",
       "2  2007년 8월 15일 아유가 프로리그 데뷔전을 치룰 때 누구와 교체되어 경기에 투...  모드스트 음바미   6539928-1-0   \n",
       "3                                  베일이 아스널과 경기했던 때는?  2010년 4월   6473562-3-1   \n",
       "4                   맨체스터 시티가 2009-10 시즌 개막전에서 이긴 팀은?   블랙번 로버스  6529318-14-1   \n",
       "\n",
       "                                             context paragraph_title  \n",
       "0  Peter Longerich 역시 막대한 연구 끝에 “유대인들은 실질적으로 어떠한 ...           홀로코스트  \n",
       "1  한편, 핵반응 기술에 대한 연구 역시 두 가지로 나뉘었다. 컬럼비아 대학교의 해럴드...          맨해튼_계획  \n",
       "2  2007년 8월 15일 발랑시엔전에서 모드스트 음바미와 89분에 교체되어 프로리그 ...          앙드레_아유  \n",
       "3  베일은 인상적인 활약을 계속해 나가며 풀럼과의 FA컵 6라운드 재경기에서 3-1 승...          가레스_베일  \n",
       "4  맨체스터 시티는 그 시즌 결국 리그 10위로 마감하였고 휴스는 팀을 더욱더 강화시키...      맨체스터_시티_FC  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = korquad_to_dataframe(train_data)\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  context  answer\n",
       "False     False    False     66181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[['question', 'context', 'answer']]\n",
    "df_dev = df_dev[['question', 'context', 'answer']]\n",
    "\n",
    "df = pd.concat([df_train, df_dev], axis=0).reset_index(drop=True)\n",
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.46.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.65 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support = Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # choose any number > 0; Suggested 8, 16, 32, 64, 128 (LoRA Rank)\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\", # \"unsloth\" or \"True\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False, # support rank static LoRA,\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "def format_example(row):\n",
    "    prompt = f\"\"\"{row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]}\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>방위비분담협정은 어디까지나 주한미군 주둔 비용에 관한 협상이라고 선을 그은 나라는?</td>\n",
       "      <td>4월에도 협상이 이어져 11일 ~ 12일 제주특별자치도에서 2차 회의가 진행되었다....</td>\n",
       "      <td>한국</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1361년 기존의 법이 강화되어 추가된 벌칙을 쓰시오.</td>\n",
       "      <td>당국은 긴급 법안(1349년의 노동자 조례와 1351년의 노동자 법령)을 통과시킴으...</td>\n",
       "      <td>단근질과 투옥</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>마리우스가 로마로 진격한 시기는 언제인가?</td>\n",
       "      <td>로마에서는 술라를 지지하는 보수파들과 루키우스 코르넬리우스 킨나를 지지하는 민중파 ...</td>\n",
       "      <td>기원전 87년 말</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>문벌 출신들이 받았던 특혜는?</td>\n",
       "      <td>문벌 출신은 유리한 교육상의 여건으로 다수의 과거 합격자를 배출하였다. 또한 이들은...</td>\n",
       "      <td>음서</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>조비의 소문을 이용하여 황제가 된 인물은?</td>\n",
       "      <td>조비는 220년 정월 조조의 죽음으로 위왕의 자리를 이어받았고, 조조의 지위를 승계...</td>\n",
       "      <td>유비(劉備)</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "0  방위비분담협정은 어디까지나 주한미군 주둔 비용에 관한 협상이라고 선을 그은 나라는?   \n",
       "1                  1361년 기존의 법이 강화되어 추가된 벌칙을 쓰시오.   \n",
       "2                        마리우스가 로마로 진격한 시기는 언제인가?    \n",
       "3                                문벌 출신들이 받았던 특혜는?   \n",
       "4                         조비의 소문을 이용하여 황제가 된 인물은?   \n",
       "\n",
       "                                             context     answer  \\\n",
       "0  4월에도 협상이 이어져 11일 ~ 12일 제주특별자치도에서 2차 회의가 진행되었다....         한국   \n",
       "1  당국은 긴급 법안(1349년의 노동자 조례와 1351년의 노동자 법령)을 통과시킴으...    단근질과 투옥   \n",
       "2  로마에서는 술라를 지지하는 보수파들과 루키우스 코르넬리우스 킨나를 지지하는 민중파 ...  기원전 87년 말   \n",
       "3  문벌 출신은 유리한 교육상의 여건으로 다수의 과거 합격자를 배출하였다. 또한 이들은...         음서   \n",
       "4  조비는 220년 정월 조조의 죽음으로 위왕의 자리를 이어받았고, 조조의 지위를 승계...     유비(劉備)   \n",
       "\n",
       "                                                text  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df.apply(format_example, axis=1)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "방위비분담협정은 어디까지나 주한미군 주둔 비용에 관한 협상이라고 선을 그은 나라는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "4월에도 협상이 이어져 11일 ~ 12일 제주특별자치도에서 2차 회의가 진행되었다. 트럼프는 줄기차게 언급했던 안보 무임승차론을 제기하면서 전략자산 전개 비용을 한국이 부담해야 한다고 주장했으나 한국은 \"방위비분담협정은 어디까지나 주한미군 주둔 비용에 관한 협상\"이라고 선을 그었다. 외교부 관계자는 \"(1차 회의에 비해) 진전됐다기보다 서로 자신의 주장에 대한 근거나 배경을 깊이있게 얘기했다\"고 언급해 아직 이견이 크다는 것을 확인했으며, 배치 비용을 미국이 부담하는 것으로 합의한 사드 문제는 논의되지 않았다. 5월 14일 ~ 15일에는 미국 국무부 청사에서 3차 회의가 열렸다. 전략자산 전개 비용의 한국 부담 요청에 더해 미국은 방위비 분담이 현금 지원에서 현물 중심으로 개선되는 지금의 흐름이 후퇴해선 안 된다는 입장도 덧붙여서 \"아직 갈 길이 멀다\"는 평가다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "한국<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# system 프롬프트에 \n",
    "# Cutting Knowledge Date: December 2023\n",
    "# Today Date: 26 July 2024 가 추가되어 llama 3.1 프롬프트 탬플릿임을 확인\n",
    "\n",
    "print(df.loc[0,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(row):\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False\n",
    "        )[\"input_ids\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 16.7 ms, total: 37.9 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(57139, 66181, 0.8633746845771445)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "plt.hist(df['token_count'], ec='k', bins=30, weights=np.ones(len(df['token_count'])) / len(df['token_count']) )\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "len(df[df['token_count'] < 512]), len(df), len(df[df['token_count'] < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "# 토큰 길이로 적당히 학습 샘플 서브샘플링 \n",
    "df_sampled = df[df[\"token_count\"] < 512]\n",
    "df_sampled = df_sampled.sample(6000, random_state=SEED)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df_sampled, test_size=0.2, random_state=SEED)\n",
    "val, test = train_test_split(temp, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data ratio:0.8, 4800\n",
      "Valid data ratio:0.16, 960\n",
      "Test data ratio:0.04, 240\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data ratio:{len(train) / len(df_sampled)}, {len(train)}\")\n",
    "print(f\"Valid data ratio:{len(val) / len(df_sampled)}, {len(val)}\")\n",
    "print(f\"Test data ratio:{len(test) / len(df_sampled)}, {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=4000, random_state=SEED).to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=500, random_state=SEED).to_json(\"val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=100, random_state=SEED).to_json(\"test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff7d869a02c43e29864cb6ee5d292a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0021cbb7f84bff9484e3da35261319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb041c8c5fa478abd7c56dcb825726b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"train.json\",\n",
    "        \"validation\": \"val.json\",\n",
    "        \"test\": \"test.json\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = f\"\"\"{data_row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{data_row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    ) # 프롬프트 끝에 <|start_header_id|>assistant<|end_header_id|> 를 붙이게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 셋에 대해서 학습전 출력을 확인\n",
    "def inf_test_one_sample(example, model):\n",
    "    prompt = create_test_prompt(example)\n",
    "    print(\"\\nPROMPT\\n\", prompt.strip())\n",
    "    \n",
    "    inputs = torch.tensor([tokenizer(prompt)['input_ids']]).to('cuda')\n",
    "\n",
    "    outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
    "                         temperature = 1.5, min_p = 0.1)\n",
    "\n",
    "    print(\"\\nANS\\n\", example['answer'])\n",
    "    print(\"\\nPRED\\n\", tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip())\n",
    "\n",
    "    return example['answer'], tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip()\n",
    "\n",
    "FastLanguageModel.for_inference(model);\n",
    "untrained = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "리옹 지하철의 시간 당 이용객 수는 약 몇 명인가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "가장 많은 승객을 빠르게 이동시킬 수 있는 수단으로는 지하철이 있다. 다른 교통수단과 비교해볼때 지하철의 최대 장점은 단위시간당 수송인원이 많다는 것이다. 65명이 탑승하고 10분마다 운행하는 버스의 시간당 승객 수송량은 390명이다. 200명이 탑승하고 10분마다 운행하는 트램의 시간당 승객 수송량은 1200명이다. 600명이 탑승하고, 2분마다 운행하는 지하철의 시간당 승객 수송량은 18,000명이다. 이러한 수송량 때문에 전 세계적으로 지하철이 없는 대도시는 찾아보기 어렵다. 프랑스 리옹에서는 시간당 약 1만명이 지하철을 이용한다. 지하철의 시간당 수송 인원이 많은 이유는 전용 철로를 이용해 다니기 때문이다. 운행에 방해가 될만한 것이 없어 평균속도 75km로 달릴 수 있다. 극심한 혼잡이 빚어지는 출퇴근시간에는 2분에 한대꼴로 운행이 되기도 한다. 하지만 지하철 인프라를 구축하는데 많은 시간과 돈이 든다. 터널을 뚫고 레일을 깔고, 엘리베이터, 계단, 승강장 등을 만들어야 하기 때문에 지하철은 트램에 비해 3~5배 가량 더 많은 돈을 투자해야 한다. 건설비는 지자체와 중앙정부, 기업들의 세금, 그리고 승객들이 내는 요금으로 차츰 충당된다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANS\n",
      " 약 1만명\n",
      "\n",
      "PRED\n",
      " 리옹의 시간당 이용객 수는 10,000명입니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Append\n",
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][0], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "소울커넥션 크리스마스 디지틀싱글 제목은?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "소울 커넥션에 입단하게 된 스틸피엠은 입단 맞이 벙개송을 시작으로 이후 활발한 활동을 펼치게 된다. 당시 힙합씬에서 크게 히트한 매슬로의 [Young MAstory] 앨범에서 그가 참여한 곡은 3곡이며 당시 입단한지 1년 정도밖에 안 지난 것을 감안하면 많은 작업량인 것을 알 수 있다. 이후 그는 소울커넥션 크리스마스 맞이 디지털 싱글 [해피 크리스마스]의 타이틀 곡 [해피 크리스마스]에 참여하게 되어 더욱 더 그를 알리게 된다. 2009년 3월 소울커넥션의 첫 컴필레이션 앨범 [RapsodY]가 발매 되었는데 이때 스틸피엠은 타이틀 곡 〈Hey ma〉를 포함 무려 7곡이나 참여하여 더욱 더 소울 커넥션 내 그의 위치를 리스너들에게 각인 시켰다. 이후 소울커넥션과 Day life의 콜라보 앨범 [Day life]에서 그는 전곡에 참여하여 완전히 메인 멤버로 부상하게 된다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " [해피 크리스마스]\n",
      "\n",
      "PRED\n",
      " 소울커넥션 크리스마스 디지틀싱글의 제목은 해피 크리스마스입니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][1], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "토트넘과 유로파리그에서 경기한 상대는 누구인가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2013년 3월 3일, 베일은 토트넘이 2-1로 이긴 아스널과의 북런던 더비 경기에서 득점을 기록했다. 3월 7일, 토트넘은 UEFA 유로파리그에서 인테르나치오날레를 상대했고, 베일이 토트넘의 선제골을 넣는 것을 시작으로 3-0 대승을 거두었다. 베일은 2013년 초반에 맹활약을 이어나가 2월 프리미어리그 이달의 선수상을 받은 것은 물론, BBC로부터 이 달의 골 1월과 2월에 모두 득점자로도 선정되었는데, 그는 각각 노리치 시티전과 웨스트 햄 유나이티드전에서의 득점으로 선정되었다. 4월 4일, 베일은 바젤과의 UEFA 유로파리그 8강전에서 오른쪽 발목 부상을 당했다. 부상에서 돌아온 베일은 맨체스터 시티와의 홈경기에서 자신의 득점과 클린트 뎀프시의 골을 돕는 도움을 기록했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 인테르나치오날레\n",
      "\n",
      "PRED\n",
      " UEFA 유로파 리그에서 토트넘과 경기한 상대는 인테르나치오날레가 아니었으며, 그 경기 결과는 3-0로 토트넘이 승리했다. 인테르나치오날레는 8강전에서 토트�\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][2], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "역세권 개발이 미뤄진 이유는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "이후 2007년 9월 27일, (가칭)북창원역을 비롯한 용동 일원의 규모의 북창원역 역세권 종합개발 사업을 추진할 것을 발표하여 이날 박완수 창원시장과 신희범 경상남도개발공사 사장이 상호 분담을 통하여 효율적으로 추진할 것을 골자로 하는 시정협약을 체결하였다. 이 종합개발 사업에는 고속철도 개통으로 예상되는 (가칭)북창원역 진입로 개선 문제와 함께, 정병산과 비음산을 찾는 시민들의 주차공간을 확보하고 여러 상업, 공공기관 등을 주변에 배치하여 공간체계의 효율성 등을 개선 할 수 있도록 하였다. 구체적으로는 역이 신설되는 용동저수지 일원 295,110m에 1,149억원의 예산을 투입하여, 그 가운데 절반에 해당하는 15만 2천여m에 도시기반시설을, 6만 1천여m은 상업용지로, 나머지 8만 1천여m는 기타시설용지로 구분하여 역세권개발이 추진되었다. 2007년 시행협약을 했던 당시에 이 사업은 2010년 초에 착공하여 2011년 말 경에 완공 될 예정이었지만, 그린벨트 해제에 시간이 오래 걸리면서2012년에 착공하여 2014년에 완공으로 계획이 변경되었고, 사업 시기도 2년 이상 차질을 빚었다. 이에 박완수 창원시장은 역세권 개발에 대해 특별한 대책을 강구해야 한다고 말했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 그린벨트 해제\n",
      "\n",
      "PRED\n",
      " 역세권 개발이 미뤄 진 이유는 북창원역 surrounding development를 추진하기 위하여였습니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][3], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('약 1만명', '리옹의 시간당 이용객 수는 10,000명입니다.<|eot_id|>'),\n",
       " ('[해피 크리스마스]', '소울커넥션 크리스마스 디지틀싱글의 제목은 해피 크리스마스입니다.<|eot_id|>'),\n",
       " ('인테르나치오날레',\n",
       "  'UEFA 유로파 리그에서 토트넘과 경기한 상대는 인테르나치오날레가 아니었으며, 그 경기 결과는 3-0로 토트넘이 승리했다. 인테르나치오날레는 8강전에서 토트�'),\n",
       " ('그린벨트 해제',\n",
       "  '역세권 개발이 미뤄 진 이유는 북창원역 surrounding development를 추진하기 위하여였습니다.<|eot_id|>')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(lora_model);\n",
    "FastLanguageModel.for_training(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c806c366b3944108e7acea24fc63e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ef673487a846859776ea9b27f7b4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgyukim/.conda/envs/Llama/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99aa0b59a0d46d6a729865b0096ae80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a3a867e04c499a82e2fdc18f4b4b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Trainer \n",
    "trainer = SFTTrainer(\n",
    "    model = lora_model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 1,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.2,\n",
    "        save_steps=0.2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "통일민주당을 장학하고 대통령 선거 출마 선언을 한 사람은?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "9월 29일에는 김영삼 총재, 김대중 고문 간 후보단일화 회담을 하였으나 이견차이를 좁히지 못하고 결렬되었다. 9월 30일 김대중은 다시 제13대 대통령 선거 후보 출마를 김영삼과 야당 후보단일화 협상을 벌였으나 양자간의 시각차이만 확인하고 결렬되었다. 재야 인사들의 통합 요청에도 불구하고 협상이 결렬되자, 이는 군사 정권 후계자를 놓고 야당 지도자간 분열했다 하여 적전 분열이라는 비판을 초래하였다. 10월 10일, 통일민주당을 장악한 김영삼은 대통령 선거 출마를 발표하고 나서자 당내 경선에서 절대적으로 불리한 위치에 놓여있던 김대중은 10월 18일 통일민주당을 탈당하였다. 11월 12일에는 평화민주당을 창당해 대표 겸 13대 대통령 후보로 선출된 이후 야당 후보였던 김영삼과 후보 단일화를 이루지 못한 채 12월 16일에 제13대 대통령 선거에 출마했지만, 노태우와 김영삼에게 밀려 611만 표를 얻고 낙선했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "김영삼<|eot_id|>\n",
      "                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\n",
      "김영삼<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(trainer.train_dataset[5][\"input_ids\"]))\n",
    "\n",
    "# trainer.train_dataset의 labels에는 instruction에 해당하는 입력부분은 모두 -100으로\n",
    "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
    "print(tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 4,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcallingu\u001b[0m (\u001b[33m3d_nerf\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mgyukim/workspaces/courses/LLAMA/wandb/run-20241030_072723-j68h4wds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/3d_nerf/huggingface/runs/j68h4wds' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/3d_nerf/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/3d_nerf/huggingface' target=\"_blank\">https://wandb.ai/3d_nerf/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/3d_nerf/huggingface/runs/j68h4wds' target=\"_blank\">https://wandb.ai/3d_nerf/huggingface/runs/j68h4wds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 08:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.223015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.184050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.167549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.158417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.157640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained = []\n",
    "FastLanguageModel.for_inference(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "리옹 지하철의 시간 당 이용객 수는 약 몇 명인가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "가장 많은 승객을 빠르게 이동시킬 수 있는 수단으로는 지하철이 있다. 다른 교통수단과 비교해볼때 지하철의 최대 장점은 단위시간당 수송인원이 많다는 것이다. 65명이 탑승하고 10분마다 운행하는 버스의 시간당 승객 수송량은 390명이다. 200명이 탑승하고 10분마다 운행하는 트램의 시간당 승객 수송량은 1200명이다. 600명이 탑승하고, 2분마다 운행하는 지하철의 시간당 승객 수송량은 18,000명이다. 이러한 수송량 때문에 전 세계적으로 지하철이 없는 대도시는 찾아보기 어렵다. 프랑스 리옹에서는 시간당 약 1만명이 지하철을 이용한다. 지하철의 시간당 수송 인원이 많은 이유는 전용 철로를 이용해 다니기 때문이다. 운행에 방해가 될만한 것이 없어 평균속도 75km로 달릴 수 있다. 극심한 혼잡이 빚어지는 출퇴근시간에는 2분에 한대꼴로 운행이 되기도 한다. 하지만 지하철 인프라를 구축하는데 많은 시간과 돈이 든다. 터널을 뚫고 레일을 깔고, 엘리베이터, 계단, 승강장 등을 만들어야 하기 때문에 지하철은 트램에 비해 3~5배 가량 더 많은 돈을 투자해야 한다. 건설비는 지자체와 중앙정부, 기업들의 세금, 그리고 승객들이 내는 요금으로 차츰 충당된다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 약 1만명\n",
      "\n",
      "PRED\n",
      " 1만명<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][0], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "소울커넥션 크리스마스 디지틀싱글 제목은?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "소울 커넥션에 입단하게 된 스틸피엠은 입단 맞이 벙개송을 시작으로 이후 활발한 활동을 펼치게 된다. 당시 힙합씬에서 크게 히트한 매슬로의 [Young MAstory] 앨범에서 그가 참여한 곡은 3곡이며 당시 입단한지 1년 정도밖에 안 지난 것을 감안하면 많은 작업량인 것을 알 수 있다. 이후 그는 소울커넥션 크리스마스 맞이 디지털 싱글 [해피 크리스마스]의 타이틀 곡 [해피 크리스마스]에 참여하게 되어 더욱 더 그를 알리게 된다. 2009년 3월 소울커넥션의 첫 컴필레이션 앨범 [RapsodY]가 발매 되었는데 이때 스틸피엠은 타이틀 곡 〈Hey ma〉를 포함 무려 7곡이나 참여하여 더욱 더 소울 커넥션 내 그의 위치를 리스너들에게 각인 시켰다. 이후 소울커넥션과 Day life의 콜라보 앨범 [Day life]에서 그는 전곡에 참여하여 완전히 메인 멤버로 부상하게 된다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " [해피 크리스마스]\n",
      "\n",
      "PRED\n",
      " 해피 크리스마스<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][1], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "토트넘과 유로파리그에서 경기한 상대는 누구인가?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2013년 3월 3일, 베일은 토트넘이 2-1로 이긴 아스널과의 북런던 더비 경기에서 득점을 기록했다. 3월 7일, 토트넘은 UEFA 유로파리그에서 인테르나치오날레를 상대했고, 베일이 토트넘의 선제골을 넣는 것을 시작으로 3-0 대승을 거두었다. 베일은 2013년 초반에 맹활약을 이어나가 2월 프리미어리그 이달의 선수상을 받은 것은 물론, BBC로부터 이 달의 골 1월과 2월에 모두 득점자로도 선정되었는데, 그는 각각 노리치 시티전과 웨스트 햄 유나이티드전에서의 득점으로 선정되었다. 4월 4일, 베일은 바젤과의 UEFA 유로파리그 8강전에서 오른쪽 발목 부상을 당했다. 부상에서 돌아온 베일은 맨체스터 시티와의 홈경기에서 자신의 득점과 클린트 뎀프시의 골을 돕는 도움을 기록했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 인테르나치오날레\n",
      "\n",
      "PRED\n",
      " 인테르나치오날레<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][2], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "역세권 개발이 미뤄진 이유는?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "이후 2007년 9월 27일, (가칭)북창원역을 비롯한 용동 일원의 규모의 북창원역 역세권 종합개발 사업을 추진할 것을 발표하여 이날 박완수 창원시장과 신희범 경상남도개발공사 사장이 상호 분담을 통하여 효율적으로 추진할 것을 골자로 하는 시정협약을 체결하였다. 이 종합개발 사업에는 고속철도 개통으로 예상되는 (가칭)북창원역 진입로 개선 문제와 함께, 정병산과 비음산을 찾는 시민들의 주차공간을 확보하고 여러 상업, 공공기관 등을 주변에 배치하여 공간체계의 효율성 등을 개선 할 수 있도록 하였다. 구체적으로는 역이 신설되는 용동저수지 일원 295,110m에 1,149억원의 예산을 투입하여, 그 가운데 절반에 해당하는 15만 2천여m에 도시기반시설을, 6만 1천여m은 상업용지로, 나머지 8만 1천여m는 기타시설용지로 구분하여 역세권개발이 추진되었다. 2007년 시행협약을 했던 당시에 이 사업은 2010년 초에 착공하여 2011년 말 경에 완공 될 예정이었지만, 그린벨트 해제에 시간이 오래 걸리면서2012년에 착공하여 2014년에 완공으로 계획이 변경되었고, 사업 시기도 2년 이상 차질을 빚었다. 이에 박완수 창원시장은 역세권 개발에 대해 특별한 대책을 강구해야 한다고 말했다.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " 그린벨트 해제\n",
      "\n",
      "PRED\n",
      " 역세권 종합개발<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][3], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정답</th>\n",
       "      <th>학습전 출력</th>\n",
       "      <th>학습후 출력</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>약 1만명</td>\n",
       "      <td>리옹의 시간당 이용객 수는 10,000명입니다.&lt;|eot_id|&gt;</td>\n",
       "      <td>1만명&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[해피 크리스마스]</td>\n",
       "      <td>소울커넥션 크리스마스 디지틀싱글의 제목은 해피 크리스마스입니다.&lt;|eot_id|&gt;</td>\n",
       "      <td>해피 크리스마스&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인테르나치오날레</td>\n",
       "      <td>UEFA 유로파 리그에서 토트넘과 경기한 상대는 인테르나치오날레가 아니었으며, 그 ...</td>\n",
       "      <td>인테르나치오날레&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그린벨트 해제</td>\n",
       "      <td>역세권 개발이 미뤄 진 이유는 북창원역 surrounding development를...</td>\n",
       "      <td>역세권 종합개발&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           정답                                             학습전 출력  \\\n",
       "0       약 1만명               리옹의 시간당 이용객 수는 10,000명입니다.<|eot_id|>   \n",
       "1  [해피 크리스마스]      소울커넥션 크리스마스 디지틀싱글의 제목은 해피 크리스마스입니다.<|eot_id|>   \n",
       "2    인테르나치오날레  UEFA 유로파 리그에서 토트넘과 경기한 상대는 인테르나치오날레가 아니었으며, 그 ...   \n",
       "3     그린벨트 해제  역세권 개발이 미뤄 진 이유는 북창원역 surrounding development를...   \n",
       "\n",
       "               학습후 출력  \n",
       "0       1만명<|eot_id|>  \n",
       "1  해피 크리스마스<|eot_id|>  \n",
       "2  인테르나치오날레<|eot_id|>  \n",
       "3  역세권 종합개발<|eot_id|>  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[(utrd[0], utrd[1], trd[1]) for utrd, trd in zip(untrained, trained)],\n",
    "    columns=['정답', '학습전 출력', '학습후 출력']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
