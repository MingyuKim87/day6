{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_train.json -O KorQuAD_v1.0_train.json\n",
    "# !wget https://raw.githubusercontent.com/korquad/korquad.github.io/master/dataset/KorQuAD_v1.0_dev.json -O KorQuAD_v1.0_dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"]=\"1\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./KorQuAD_v1.0_dev.json', 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open('./KorQuAD_v1.0_train.json', 'r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def korquad_to_dataframe(data):\n",
    "    rows = []\n",
    "    for paragraph in data['data']:\n",
    "        paragraph_title = paragraph['title']\n",
    "\n",
    "        for qa in paragraph['paragraphs']:\n",
    "            context = qa['context']\n",
    "\n",
    "            for question in qa['qas']:\n",
    "                q = question['question']\n",
    "                qa_id = question['id']\n",
    "\n",
    "                for answer in question['answers']:\n",
    "                    a = answer['text']\n",
    "                    rows.append({\n",
    "                        'question': q,\n",
    "                        'answer': a,\n",
    "                        'qa_id': qa_id,\n",
    "                        'context': context,\n",
    "                        'paragraph_title': paragraph_title\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5774, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ëª…ì˜ˆì˜ ì „ë‹¹ì— ë“¤ì–´ê°€ë ¤ë©´ ì€í‡´ í›„ ëª‡ë…„ì´ ì§€ë‚˜ì•¼ í•˜ëŠ”ê°€?</td>\n",
       "      <td>5ë…„</td>\n",
       "      <td>6469691-2-1</td>\n",
       "      <td>300 ìŠ¹ì€ ì•¼êµ¬ ëª…ì˜ˆì˜ ì „ë‹¹ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ë³´ì¦ ìˆ˜í‘œì²˜ëŸ¼ ì—¬ê²¨ì§€ëŠ”ë°, ì´ íˆ¬ìˆ˜...</td>\n",
       "      <td>300_ìŠ¹_í´ëŸ½</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ìœ¤ìƒì´ ë‚˜ë ˆì´ì…˜ì„ ë§¡ì€ EBS ë‹¤íí”„ë¼ì„ ì œëª©ì€ ë¬´ì—‡ì¸ê°€?</td>\n",
       "      <td>í•œêµ­ì˜ ê°•</td>\n",
       "      <td>5835201-5-2</td>\n",
       "      <td>2010ë…„ 3ì›”ì—ëŠ” ë‰´ìš•ì—ì„œ ëŒ€í•™ì›ì„ ì¡¸ì—…í•˜ê³  ìœ í•™ ìƒí™œì„ ì •ë¦¬í•œ ë’¤ ê·€êµ­í•˜ì—¬ ìƒëª…...</td>\n",
       "      <td>ìœ¤ìƒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì•ˆì „ê¸°ìˆ ì˜ ì›ì „ í™•ì¥ì„ ìœ„í•´ ê°œë°œë˜ëŠ” ê²ƒì€?</td>\n",
       "      <td>ìƒìš©ê²½ìˆ˜ë¡œ</td>\n",
       "      <td>6588949-2-1</td>\n",
       "      <td>ë¯¸ë˜ì „ëµê¸°ìˆ  ê°œë°œì„ ìœ„í•´ì„œ ë¨¼ì € ì‹ ê¸°ìˆ  ìœµí•©Â·ì ‘ëª©ì„ í†µí•œ ìƒˆë¡œìš´ ì›ìë ¥ ì˜ì—­ ê°œì²™ì´...</td>\n",
       "      <td>ì›ìë ¥ì§„í¥ì¢…í•©ê³„íš</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì´ëª…ë°•ì´ êµ°ëŒ€ ì…ëŒ€ í›„ í›ˆë ¨ì†Œì—ì„œ ê°•ì œ í‡´ì†Œ ë‹¹í•œ ì´ìœ ëŠ”?</td>\n",
       "      <td>ê¸°ê´€ì§€í™•ì¥ì¦</td>\n",
       "      <td>6545197-0-0</td>\n",
       "      <td>ì´íƒœì›ì‹œì¥ì—ì„œ ë§¤ì¼ ìƒˆë²½ ì²­ì†Œ ì¼ì„ í•˜ëŠ” í™˜ê²½ë¯¸í™”ì›ìœ¼ë¡œ í•™ì—…ì„ ì´ì–´ê°€ë˜ ì¤‘ ìƒí™œê³ ë¥¼...</td>\n",
       "      <td>ì´ëª…ë°•</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970ë…„ ë„¤ëœë€ë“œ ê·¸ë‘í”„ë¦¬ì—ì„œ ì‚¬ë§í•œ ì„ ìˆ˜ëŠ”?</td>\n",
       "      <td>í”¼ì–´ìŠ¤ ì»¤ë¦¬ì§€</td>\n",
       "      <td>6464976-3-0</td>\n",
       "      <td>í•˜ì§€ë§Œ ì–¸ì œë‚˜ ìˆœì¡°ë¡­ì§€ë§Œì€ ì•Šì•˜ë‹¤. 1970ë…„ í”¼ì–´ìŠ¤ ì»¤ë¦¬ì§€(Piers Courag...</td>\n",
       "      <td>ë‰˜ë¥´ë¶€ë¥´í¬ë§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question   answer        qa_id  \\\n",
       "0    ëª…ì˜ˆì˜ ì „ë‹¹ì— ë“¤ì–´ê°€ë ¤ë©´ ì€í‡´ í›„ ëª‡ë…„ì´ ì§€ë‚˜ì•¼ í•˜ëŠ”ê°€?       5ë…„  6469691-2-1   \n",
       "1  ìœ¤ìƒì´ ë‚˜ë ˆì´ì…˜ì„ ë§¡ì€ EBS ë‹¤íí”„ë¼ì„ ì œëª©ì€ ë¬´ì—‡ì¸ê°€?     í•œêµ­ì˜ ê°•  5835201-5-2   \n",
       "2           ì•ˆì „ê¸°ìˆ ì˜ ì›ì „ í™•ì¥ì„ ìœ„í•´ ê°œë°œë˜ëŠ” ê²ƒì€?    ìƒìš©ê²½ìˆ˜ë¡œ  6588949-2-1   \n",
       "3   ì´ëª…ë°•ì´ êµ°ëŒ€ ì…ëŒ€ í›„ í›ˆë ¨ì†Œì—ì„œ ê°•ì œ í‡´ì†Œ ë‹¹í•œ ì´ìœ ëŠ”?   ê¸°ê´€ì§€í™•ì¥ì¦  6545197-0-0   \n",
       "4         1970ë…„ ë„¤ëœë€ë“œ ê·¸ë‘í”„ë¦¬ì—ì„œ ì‚¬ë§í•œ ì„ ìˆ˜ëŠ”?  í”¼ì–´ìŠ¤ ì»¤ë¦¬ì§€  6464976-3-0   \n",
       "\n",
       "                                             context paragraph_title  \n",
       "0  300 ìŠ¹ì€ ì•¼êµ¬ ëª…ì˜ˆì˜ ì „ë‹¹ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ë³´ì¦ ìˆ˜í‘œì²˜ëŸ¼ ì—¬ê²¨ì§€ëŠ”ë°, ì´ íˆ¬ìˆ˜...        300_ìŠ¹_í´ëŸ½  \n",
       "1  2010ë…„ 3ì›”ì—ëŠ” ë‰´ìš•ì—ì„œ ëŒ€í•™ì›ì„ ì¡¸ì—…í•˜ê³  ìœ í•™ ìƒí™œì„ ì •ë¦¬í•œ ë’¤ ê·€êµ­í•˜ì—¬ ìƒëª…...              ìœ¤ìƒ  \n",
       "2  ë¯¸ë˜ì „ëµê¸°ìˆ  ê°œë°œì„ ìœ„í•´ì„œ ë¨¼ì € ì‹ ê¸°ìˆ  ìœµí•©Â·ì ‘ëª©ì„ í†µí•œ ìƒˆë¡œìš´ ì›ìë ¥ ì˜ì—­ ê°œì²™ì´...       ì›ìë ¥ì§„í¥ì¢…í•©ê³„íš  \n",
       "3  ì´íƒœì›ì‹œì¥ì—ì„œ ë§¤ì¼ ìƒˆë²½ ì²­ì†Œ ì¼ì„ í•˜ëŠ” í™˜ê²½ë¯¸í™”ì›ìœ¼ë¡œ í•™ì—…ì„ ì´ì–´ê°€ë˜ ì¤‘ ìƒí™œê³ ë¥¼...             ì´ëª…ë°•  \n",
       "4  í•˜ì§€ë§Œ ì–¸ì œë‚˜ ìˆœì¡°ë¡­ì§€ë§Œì€ ì•Šì•˜ë‹¤. 1970ë…„ í”¼ì–´ìŠ¤ ì»¤ë¦¬ì§€(Piers Courag...          ë‰˜ë¥´ë¶€ë¥´í¬ë§  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = korquad_to_dataframe(dev_data)\n",
    "df_dev = df_dev.sample(frac=1).reset_index(drop=True)\n",
    "print(df_dev.shape)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60407, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilbergì€ ìœ ëŒ€ì¸ ë°•í•´ë¥¼ í†µí•´ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ìœ ëŒ€ì¸ë“¤ì˜ ì„±í–¥ì„ ë¬´ì—‡ì´ë¼ê³  í–ˆëŠ”ê°€?</td>\n",
       "      <td>ìˆœì‘ì ì¸ íƒœë„</td>\n",
       "      <td>6571960-23-1</td>\n",
       "      <td>Peter Longerich ì—­ì‹œ ë§‰ëŒ€í•œ ì—°êµ¬ ëì— â€œìœ ëŒ€ì¸ë“¤ì€ ì‹¤ì§ˆì ìœ¼ë¡œ ì–´ë– í•œ ...</td>\n",
       "      <td>í™€ë¡œì½”ìŠ¤íŠ¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì•¼ê¸ˆ ì—°êµ¬ì†Œê°€ ì¤‘ì„±ì ê°ì†ì¬ë¡œ ì‚¬ìš©í•œ ê²ƒì€?</td>\n",
       "      <td>í‘ì—°</td>\n",
       "      <td>6502200-4-0</td>\n",
       "      <td>í•œí¸, í•µë°˜ì‘ ê¸°ìˆ ì— ëŒ€í•œ ì—°êµ¬ ì—­ì‹œ ë‘ ê°€ì§€ë¡œ ë‚˜ë‰˜ì—ˆë‹¤. ì»¬ëŸ¼ë¹„ì•„ ëŒ€í•™êµì˜ í•´ëŸ´ë“œ...</td>\n",
       "      <td>ë§¨í•´íŠ¼_ê³„íš</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007ë…„ 8ì›” 15ì¼ ì•„ìœ ê°€ í”„ë¡œë¦¬ê·¸ ë°ë·”ì „ì„ ì¹˜ë£° ë•Œ ëˆ„êµ¬ì™€ êµì²´ë˜ì–´ ê²½ê¸°ì— íˆ¬...</td>\n",
       "      <td>ëª¨ë“œìŠ¤íŠ¸ ìŒë°”ë¯¸</td>\n",
       "      <td>6539928-1-0</td>\n",
       "      <td>2007ë…„ 8ì›” 15ì¼ ë°œë‘ì‹œì—”ì „ì—ì„œ ëª¨ë“œìŠ¤íŠ¸ ìŒë°”ë¯¸ì™€ 89ë¶„ì— êµì²´ë˜ì–´ í”„ë¡œë¦¬ê·¸ ...</td>\n",
       "      <td>ì•™ë“œë ˆ_ì•„ìœ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë² ì¼ì´ ì•„ìŠ¤ë„ê³¼ ê²½ê¸°í–ˆë˜ ë•ŒëŠ”?</td>\n",
       "      <td>2010ë…„ 4ì›”</td>\n",
       "      <td>6473562-3-1</td>\n",
       "      <td>ë² ì¼ì€ ì¸ìƒì ì¸ í™œì•½ì„ ê³„ì†í•´ ë‚˜ê°€ë©° í’€ëŸ¼ê³¼ì˜ FAì»µ 6ë¼ìš´ë“œ ì¬ê²½ê¸°ì—ì„œ 3-1 ìŠ¹...</td>\n",
       "      <td>ê°€ë ˆìŠ¤_ë² ì¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë§¨ì²´ìŠ¤í„° ì‹œí‹°ê°€ 2009-10 ì‹œì¦Œ ê°œë§‰ì „ì—ì„œ ì´ê¸´ íŒ€ì€?</td>\n",
       "      <td>ë¸”ë™ë²ˆ ë¡œë²„ìŠ¤</td>\n",
       "      <td>6529318-14-1</td>\n",
       "      <td>ë§¨ì²´ìŠ¤í„° ì‹œí‹°ëŠ” ê·¸ ì‹œì¦Œ ê²°êµ­ ë¦¬ê·¸ 10ìœ„ë¡œ ë§ˆê°í•˜ì˜€ê³  íœ´ìŠ¤ëŠ” íŒ€ì„ ë”ìš±ë” ê°•í™”ì‹œí‚¤...</td>\n",
       "      <td>ë§¨ì²´ìŠ¤í„°_ì‹œí‹°_FC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question    answer         qa_id  \\\n",
       "0  Hilbergì€ ìœ ëŒ€ì¸ ë°•í•´ë¥¼ í†µí•´ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ìœ ëŒ€ì¸ë“¤ì˜ ì„±í–¥ì„ ë¬´ì—‡ì´ë¼ê³  í–ˆëŠ”ê°€?   ìˆœì‘ì ì¸ íƒœë„  6571960-23-1   \n",
       "1                           ì•¼ê¸ˆ ì—°êµ¬ì†Œê°€ ì¤‘ì„±ì ê°ì†ì¬ë¡œ ì‚¬ìš©í•œ ê²ƒì€?        í‘ì—°   6502200-4-0   \n",
       "2  2007ë…„ 8ì›” 15ì¼ ì•„ìœ ê°€ í”„ë¡œë¦¬ê·¸ ë°ë·”ì „ì„ ì¹˜ë£° ë•Œ ëˆ„êµ¬ì™€ êµì²´ë˜ì–´ ê²½ê¸°ì— íˆ¬...  ëª¨ë“œìŠ¤íŠ¸ ìŒë°”ë¯¸   6539928-1-0   \n",
       "3                                  ë² ì¼ì´ ì•„ìŠ¤ë„ê³¼ ê²½ê¸°í–ˆë˜ ë•ŒëŠ”?  2010ë…„ 4ì›”   6473562-3-1   \n",
       "4                   ë§¨ì²´ìŠ¤í„° ì‹œí‹°ê°€ 2009-10 ì‹œì¦Œ ê°œë§‰ì „ì—ì„œ ì´ê¸´ íŒ€ì€?   ë¸”ë™ë²ˆ ë¡œë²„ìŠ¤  6529318-14-1   \n",
       "\n",
       "                                             context paragraph_title  \n",
       "0  Peter Longerich ì—­ì‹œ ë§‰ëŒ€í•œ ì—°êµ¬ ëì— â€œìœ ëŒ€ì¸ë“¤ì€ ì‹¤ì§ˆì ìœ¼ë¡œ ì–´ë– í•œ ...           í™€ë¡œì½”ìŠ¤íŠ¸  \n",
       "1  í•œí¸, í•µë°˜ì‘ ê¸°ìˆ ì— ëŒ€í•œ ì—°êµ¬ ì—­ì‹œ ë‘ ê°€ì§€ë¡œ ë‚˜ë‰˜ì—ˆë‹¤. ì»¬ëŸ¼ë¹„ì•„ ëŒ€í•™êµì˜ í•´ëŸ´ë“œ...          ë§¨í•´íŠ¼_ê³„íš  \n",
       "2  2007ë…„ 8ì›” 15ì¼ ë°œë‘ì‹œì—”ì „ì—ì„œ ëª¨ë“œìŠ¤íŠ¸ ìŒë°”ë¯¸ì™€ 89ë¶„ì— êµì²´ë˜ì–´ í”„ë¡œë¦¬ê·¸ ...          ì•™ë“œë ˆ_ì•„ìœ   \n",
       "3  ë² ì¼ì€ ì¸ìƒì ì¸ í™œì•½ì„ ê³„ì†í•´ ë‚˜ê°€ë©° í’€ëŸ¼ê³¼ì˜ FAì»µ 6ë¼ìš´ë“œ ì¬ê²½ê¸°ì—ì„œ 3-1 ìŠ¹...          ê°€ë ˆìŠ¤_ë² ì¼  \n",
       "4  ë§¨ì²´ìŠ¤í„° ì‹œí‹°ëŠ” ê·¸ ì‹œì¦Œ ê²°êµ­ ë¦¬ê·¸ 10ìœ„ë¡œ ë§ˆê°í•˜ì˜€ê³  íœ´ìŠ¤ëŠ” íŒ€ì„ ë”ìš±ë” ê°•í™”ì‹œí‚¤...      ë§¨ì²´ìŠ¤í„°_ì‹œí‹°_FC  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = korquad_to_dataframe(train_data)\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  context  answer\n",
       "False     False    False     66181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[['question', 'context', 'answer']]\n",
    "df_dev = df_dev[['question', 'context', 'answer']]\n",
    "\n",
    "df = pd.concat([df_train, df_dev], axis=0).reset_index(drop=True)\n",
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.46.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.65 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support = Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # choose any number > 0; Suggested 8, 16, 32, 64, 128 (LoRA Rank)\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\", # \"unsloth\" or \"True\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False, # support rank static LoRA,\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "def format_example(row):\n",
    "    prompt = f\"\"\"{row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]}\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë°©ìœ„ë¹„ë¶„ë‹´í˜‘ì •ì€ ì–´ë””ê¹Œì§€ë‚˜ ì£¼í•œë¯¸êµ° ì£¼ë‘” ë¹„ìš©ì— ê´€í•œ í˜‘ìƒì´ë¼ê³  ì„ ì„ ê·¸ì€ ë‚˜ë¼ëŠ”?</td>\n",
       "      <td>4ì›”ì—ë„ í˜‘ìƒì´ ì´ì–´ì ¸ 11ì¼ ~ 12ì¼ ì œì£¼íŠ¹ë³„ìì¹˜ë„ì—ì„œ 2ì°¨ íšŒì˜ê°€ ì§„í–‰ë˜ì—ˆë‹¤....</td>\n",
       "      <td>í•œêµ­</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1361ë…„ ê¸°ì¡´ì˜ ë²•ì´ ê°•í™”ë˜ì–´ ì¶”ê°€ëœ ë²Œì¹™ì„ ì“°ì‹œì˜¤.</td>\n",
       "      <td>ë‹¹êµ­ì€ ê¸´ê¸‰ ë²•ì•ˆ(1349ë…„ì˜ ë…¸ë™ì ì¡°ë¡€ì™€ 1351ë…„ì˜ ë…¸ë™ì ë²•ë ¹)ì„ í†µê³¼ì‹œí‚´ìœ¼...</td>\n",
       "      <td>ë‹¨ê·¼ì§ˆê³¼ íˆ¬ì˜¥</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë§ˆë¦¬ìš°ìŠ¤ê°€ ë¡œë§ˆë¡œ ì§„ê²©í•œ ì‹œê¸°ëŠ” ì–¸ì œì¸ê°€?</td>\n",
       "      <td>ë¡œë§ˆì—ì„œëŠ” ìˆ ë¼ë¥¼ ì§€ì§€í•˜ëŠ” ë³´ìˆ˜íŒŒë“¤ê³¼ ë£¨í‚¤ìš°ìŠ¤ ì½”ë¥´ë„¬ë¦¬ìš°ìŠ¤ í‚¨ë‚˜ë¥¼ ì§€ì§€í•˜ëŠ” ë¯¼ì¤‘íŒŒ ...</td>\n",
       "      <td>ê¸°ì›ì „ 87ë…„ ë§</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë¬¸ë²Œ ì¶œì‹ ë“¤ì´ ë°›ì•˜ë˜ íŠ¹í˜œëŠ”?</td>\n",
       "      <td>ë¬¸ë²Œ ì¶œì‹ ì€ ìœ ë¦¬í•œ êµìœ¡ìƒì˜ ì—¬ê±´ìœ¼ë¡œ ë‹¤ìˆ˜ì˜ ê³¼ê±° í•©ê²©ìë¥¼ ë°°ì¶œí•˜ì˜€ë‹¤. ë˜í•œ ì´ë“¤ì€...</td>\n",
       "      <td>ìŒì„œ</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì¡°ë¹„ì˜ ì†Œë¬¸ì„ ì´ìš©í•˜ì—¬ í™©ì œê°€ ëœ ì¸ë¬¼ì€?</td>\n",
       "      <td>ì¡°ë¹„ëŠ” 220ë…„ ì •ì›” ì¡°ì¡°ì˜ ì£½ìŒìœ¼ë¡œ ìœ„ì™•ì˜ ìë¦¬ë¥¼ ì´ì–´ë°›ì•˜ê³ , ì¡°ì¡°ì˜ ì§€ìœ„ë¥¼ ìŠ¹ê³„...</td>\n",
       "      <td>ìœ ë¹„(åŠ‰å‚™)</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "0  ë°©ìœ„ë¹„ë¶„ë‹´í˜‘ì •ì€ ì–´ë””ê¹Œì§€ë‚˜ ì£¼í•œë¯¸êµ° ì£¼ë‘” ë¹„ìš©ì— ê´€í•œ í˜‘ìƒì´ë¼ê³  ì„ ì„ ê·¸ì€ ë‚˜ë¼ëŠ”?   \n",
       "1                  1361ë…„ ê¸°ì¡´ì˜ ë²•ì´ ê°•í™”ë˜ì–´ ì¶”ê°€ëœ ë²Œì¹™ì„ ì“°ì‹œì˜¤.   \n",
       "2                        ë§ˆë¦¬ìš°ìŠ¤ê°€ ë¡œë§ˆë¡œ ì§„ê²©í•œ ì‹œê¸°ëŠ” ì–¸ì œì¸ê°€?    \n",
       "3                                ë¬¸ë²Œ ì¶œì‹ ë“¤ì´ ë°›ì•˜ë˜ íŠ¹í˜œëŠ”?   \n",
       "4                         ì¡°ë¹„ì˜ ì†Œë¬¸ì„ ì´ìš©í•˜ì—¬ í™©ì œê°€ ëœ ì¸ë¬¼ì€?   \n",
       "\n",
       "                                             context     answer  \\\n",
       "0  4ì›”ì—ë„ í˜‘ìƒì´ ì´ì–´ì ¸ 11ì¼ ~ 12ì¼ ì œì£¼íŠ¹ë³„ìì¹˜ë„ì—ì„œ 2ì°¨ íšŒì˜ê°€ ì§„í–‰ë˜ì—ˆë‹¤....         í•œêµ­   \n",
       "1  ë‹¹êµ­ì€ ê¸´ê¸‰ ë²•ì•ˆ(1349ë…„ì˜ ë…¸ë™ì ì¡°ë¡€ì™€ 1351ë…„ì˜ ë…¸ë™ì ë²•ë ¹)ì„ í†µê³¼ì‹œí‚´ìœ¼...    ë‹¨ê·¼ì§ˆê³¼ íˆ¬ì˜¥   \n",
       "2  ë¡œë§ˆì—ì„œëŠ” ìˆ ë¼ë¥¼ ì§€ì§€í•˜ëŠ” ë³´ìˆ˜íŒŒë“¤ê³¼ ë£¨í‚¤ìš°ìŠ¤ ì½”ë¥´ë„¬ë¦¬ìš°ìŠ¤ í‚¨ë‚˜ë¥¼ ì§€ì§€í•˜ëŠ” ë¯¼ì¤‘íŒŒ ...  ê¸°ì›ì „ 87ë…„ ë§   \n",
       "3  ë¬¸ë²Œ ì¶œì‹ ì€ ìœ ë¦¬í•œ êµìœ¡ìƒì˜ ì—¬ê±´ìœ¼ë¡œ ë‹¤ìˆ˜ì˜ ê³¼ê±° í•©ê²©ìë¥¼ ë°°ì¶œí•˜ì˜€ë‹¤. ë˜í•œ ì´ë“¤ì€...         ìŒì„œ   \n",
       "4  ì¡°ë¹„ëŠ” 220ë…„ ì •ì›” ì¡°ì¡°ì˜ ì£½ìŒìœ¼ë¡œ ìœ„ì™•ì˜ ìë¦¬ë¥¼ ì´ì–´ë°›ì•˜ê³ , ì¡°ì¡°ì˜ ì§€ìœ„ë¥¼ ìŠ¹ê³„...     ìœ ë¹„(åŠ‰å‚™)   \n",
       "\n",
       "                                                text  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df.apply(format_example, axis=1)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ë°©ìœ„ë¹„ë¶„ë‹´í˜‘ì •ì€ ì–´ë””ê¹Œì§€ë‚˜ ì£¼í•œë¯¸êµ° ì£¼ë‘” ë¹„ìš©ì— ê´€í•œ í˜‘ìƒì´ë¼ê³  ì„ ì„ ê·¸ì€ ë‚˜ë¼ëŠ”?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "4ì›”ì—ë„ í˜‘ìƒì´ ì´ì–´ì ¸ 11ì¼ ~ 12ì¼ ì œì£¼íŠ¹ë³„ìì¹˜ë„ì—ì„œ 2ì°¨ íšŒì˜ê°€ ì§„í–‰ë˜ì—ˆë‹¤. íŠ¸ëŸ¼í”„ëŠ” ì¤„ê¸°ì°¨ê²Œ ì–¸ê¸‰í–ˆë˜ ì•ˆë³´ ë¬´ì„ìŠ¹ì°¨ë¡ ì„ ì œê¸°í•˜ë©´ì„œ ì „ëµìì‚° ì „ê°œ ë¹„ìš©ì„ í•œêµ­ì´ ë¶€ë‹´í•´ì•¼ í•œë‹¤ê³  ì£¼ì¥í–ˆìœ¼ë‚˜ í•œêµ­ì€ \"ë°©ìœ„ë¹„ë¶„ë‹´í˜‘ì •ì€ ì–´ë””ê¹Œì§€ë‚˜ ì£¼í•œë¯¸êµ° ì£¼ë‘” ë¹„ìš©ì— ê´€í•œ í˜‘ìƒ\"ì´ë¼ê³  ì„ ì„ ê·¸ì—ˆë‹¤. ì™¸êµë¶€ ê´€ê³„ìëŠ” \"(1ì°¨ íšŒì˜ì— ë¹„í•´) ì§„ì „ëë‹¤ê¸°ë³´ë‹¤ ì„œë¡œ ìì‹ ì˜ ì£¼ì¥ì— ëŒ€í•œ ê·¼ê±°ë‚˜ ë°°ê²½ì„ ê¹Šì´ìˆê²Œ ì–˜ê¸°í–ˆë‹¤\"ê³  ì–¸ê¸‰í•´ ì•„ì§ ì´ê²¬ì´ í¬ë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆìœ¼ë©°, ë°°ì¹˜ ë¹„ìš©ì„ ë¯¸êµ­ì´ ë¶€ë‹´í•˜ëŠ” ê²ƒìœ¼ë¡œ í•©ì˜í•œ ì‚¬ë“œ ë¬¸ì œëŠ” ë…¼ì˜ë˜ì§€ ì•Šì•˜ë‹¤. 5ì›” 14ì¼ ~ 15ì¼ì—ëŠ” ë¯¸êµ­ êµ­ë¬´ë¶€ ì²­ì‚¬ì—ì„œ 3ì°¨ íšŒì˜ê°€ ì—´ë ¸ë‹¤. ì „ëµìì‚° ì „ê°œ ë¹„ìš©ì˜ í•œêµ­ ë¶€ë‹´ ìš”ì²­ì— ë”í•´ ë¯¸êµ­ì€ ë°©ìœ„ë¹„ ë¶„ë‹´ì´ í˜„ê¸ˆ ì§€ì›ì—ì„œ í˜„ë¬¼ ì¤‘ì‹¬ìœ¼ë¡œ ê°œì„ ë˜ëŠ” ì§€ê¸ˆì˜ íë¦„ì´ í›„í‡´í•´ì„  ì•ˆ ëœë‹¤ëŠ” ì…ì¥ë„ ë§ë¶™ì—¬ì„œ \"ì•„ì§ ê°ˆ ê¸¸ì´ ë©€ë‹¤\"ëŠ” í‰ê°€ë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "í•œêµ­<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# system í”„ë¡¬í”„íŠ¸ì— \n",
    "# Cutting Knowledge Date: December 2023\n",
    "# Today Date: 26 July 2024 ê°€ ì¶”ê°€ë˜ì–´ llama 3.1 í”„ë¡¬í”„íŠ¸ íƒ¬í”Œë¦¿ì„ì„ í™•ì¸\n",
    "\n",
    "print(df.loc[0,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(row):\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row['text'],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False\n",
    "        )[\"input_ids\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 16.7 ms, total: 37.9 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(57139, 66181, 0.8633746845771445)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "plt.hist(df['token_count'], ec='k', bins=30, weights=np.ones(len(df['token_count'])) / len(df['token_count']) )\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "len(df[df['token_count'] < 512]), len(df), len(df[df['token_count'] < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "# í† í° ê¸¸ì´ë¡œ ì ë‹¹íˆ í•™ìŠµ ìƒ˜í”Œ ì„œë¸Œìƒ˜í”Œë§ \n",
    "df_sampled = df[df[\"token_count\"] < 512]\n",
    "df_sampled = df_sampled.sample(6000, random_state=SEED)\n",
    "df_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df_sampled, test_size=0.2, random_state=SEED)\n",
    "val, test = train_test_split(temp, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data ratio:0.8, 4800\n",
      "Valid data ratio:0.16, 960\n",
      "Test data ratio:0.04, 240\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data ratio:{len(train) / len(df_sampled)}, {len(train)}\")\n",
    "print(f\"Valid data ratio:{len(val) / len(df_sampled)}, {len(val)}\")\n",
    "print(f\"Test data ratio:{len(test) / len(df_sampled)}, {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=4000, random_state=SEED).to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=500, random_state=SEED).to_json(\"val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=100, random_state=SEED).to_json(\"test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff7d869a02c43e29864cb6ee5d292a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0021cbb7f84bff9484e3da35261319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb041c8c5fa478abd7c56dcb825726b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"train.json\",\n",
    "        \"validation\": \"val.json\",\n",
    "        \"test\": \"test.json\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text', 'token_count'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = f\"\"\"{data_row[\"question\"]}\n",
    "\n",
    "Information\n",
    "\n",
    "###\n",
    "{data_row[\"context\"]}\n",
    "###\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    ) # í”„ë¡¬í”„íŠ¸ ëì— <|start_header_id|>assistant<|end_header_id|> ë¥¼ ë¶™ì´ê²Œ ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì…‹ì— ëŒ€í•´ì„œ í•™ìŠµì „ ì¶œë ¥ì„ í™•ì¸\n",
    "def inf_test_one_sample(example, model):\n",
    "    prompt = create_test_prompt(example)\n",
    "    print(\"\\nPROMPT\\n\", prompt.strip())\n",
    "    \n",
    "    inputs = torch.tensor([tokenizer(prompt)['input_ids']]).to('cuda')\n",
    "\n",
    "    outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
    "                         temperature = 1.5, min_p = 0.1)\n",
    "\n",
    "    print(\"\\nANS\\n\", example['answer'])\n",
    "    print(\"\\nPRED\\n\", tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip())\n",
    "\n",
    "    return example['answer'], tokenizer.batch_decode(outputs)[0].split('<|start_header_id|>assistant<|end_header_id|>')[1].strip()\n",
    "\n",
    "FastLanguageModel.for_inference(model);\n",
    "untrained = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ë¦¬ì˜¹ ì§€í•˜ì² ì˜ ì‹œê°„ ë‹¹ ì´ìš©ê° ìˆ˜ëŠ” ì•½ ëª‡ ëª…ì¸ê°€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ê°€ì¥ ë§ì€ ìŠ¹ê°ì„ ë¹ ë¥´ê²Œ ì´ë™ì‹œí‚¬ ìˆ˜ ìˆëŠ” ìˆ˜ë‹¨ìœ¼ë¡œëŠ” ì§€í•˜ì² ì´ ìˆë‹¤. ë‹¤ë¥¸ êµí†µìˆ˜ë‹¨ê³¼ ë¹„êµí•´ë³¼ë•Œ ì§€í•˜ì² ì˜ ìµœëŒ€ ì¥ì ì€ ë‹¨ìœ„ì‹œê°„ë‹¹ ìˆ˜ì†¡ì¸ì›ì´ ë§ë‹¤ëŠ” ê²ƒì´ë‹¤. 65ëª…ì´ íƒ‘ìŠ¹í•˜ê³  10ë¶„ë§ˆë‹¤ ìš´í–‰í•˜ëŠ” ë²„ìŠ¤ì˜ ì‹œê°„ë‹¹ ìŠ¹ê° ìˆ˜ì†¡ëŸ‰ì€ 390ëª…ì´ë‹¤. 200ëª…ì´ íƒ‘ìŠ¹í•˜ê³  10ë¶„ë§ˆë‹¤ ìš´í–‰í•˜ëŠ” íŠ¸ë¨ì˜ ì‹œê°„ë‹¹ ìŠ¹ê° ìˆ˜ì†¡ëŸ‰ì€ 1200ëª…ì´ë‹¤. 600ëª…ì´ íƒ‘ìŠ¹í•˜ê³ , 2ë¶„ë§ˆë‹¤ ìš´í–‰í•˜ëŠ” ì§€í•˜ì² ì˜ ì‹œê°„ë‹¹ ìŠ¹ê° ìˆ˜ì†¡ëŸ‰ì€ 18,000ëª…ì´ë‹¤. ì´ëŸ¬í•œ ìˆ˜ì†¡ëŸ‰ ë•Œë¬¸ì— ì „ ì„¸ê³„ì ìœ¼ë¡œ ì§€í•˜ì² ì´ ì—†ëŠ” ëŒ€ë„ì‹œëŠ” ì°¾ì•„ë³´ê¸° ì–´ë µë‹¤. í”„ë‘ìŠ¤ ë¦¬ì˜¹ì—ì„œëŠ” ì‹œê°„ë‹¹ ì•½ 1ë§Œëª…ì´ ì§€í•˜ì² ì„ ì´ìš©í•œë‹¤. ì§€í•˜ì² ì˜ ì‹œê°„ë‹¹ ìˆ˜ì†¡ ì¸ì›ì´ ë§ì€ ì´ìœ ëŠ” ì „ìš© ì² ë¡œë¥¼ ì´ìš©í•´ ë‹¤ë‹ˆê¸° ë•Œë¬¸ì´ë‹¤. ìš´í–‰ì— ë°©í•´ê°€ ë ë§Œí•œ ê²ƒì´ ì—†ì–´ í‰ê· ì†ë„ 75kmë¡œ ë‹¬ë¦´ ìˆ˜ ìˆë‹¤. ê·¹ì‹¬í•œ í˜¼ì¡ì´ ë¹šì–´ì§€ëŠ” ì¶œí‡´ê·¼ì‹œê°„ì—ëŠ” 2ë¶„ì— í•œëŒ€ê¼´ë¡œ ìš´í–‰ì´ ë˜ê¸°ë„ í•œë‹¤. í•˜ì§€ë§Œ ì§€í•˜ì²  ì¸í”„ë¼ë¥¼ êµ¬ì¶•í•˜ëŠ”ë° ë§ì€ ì‹œê°„ê³¼ ëˆì´ ë“ ë‹¤. í„°ë„ì„ ëš«ê³  ë ˆì¼ì„ ê¹”ê³ , ì—˜ë¦¬ë² ì´í„°, ê³„ë‹¨, ìŠ¹ê°•ì¥ ë“±ì„ ë§Œë“¤ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì§€í•˜ì² ì€ íŠ¸ë¨ì— ë¹„í•´ 3~5ë°° ê°€ëŸ‰ ë” ë§ì€ ëˆì„ íˆ¬ìí•´ì•¼ í•œë‹¤. ê±´ì„¤ë¹„ëŠ” ì§€ìì²´ì™€ ì¤‘ì•™ì •ë¶€, ê¸°ì—…ë“¤ì˜ ì„¸ê¸ˆ, ê·¸ë¦¬ê³  ìŠ¹ê°ë“¤ì´ ë‚´ëŠ” ìš”ê¸ˆìœ¼ë¡œ ì°¨ì¸° ì¶©ë‹¹ëœë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANS\n",
      " ì•½ 1ë§Œëª…\n",
      "\n",
      "PRED\n",
      " ë¦¬ì˜¹ì˜ ì‹œê°„ë‹¹ ì´ìš©ê° ìˆ˜ëŠ” 10,000ëª…ì…ë‹ˆë‹¤.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Append\n",
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][0], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë””ì§€í‹€ì‹±ê¸€ ì œëª©ì€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ì†Œìš¸ ì»¤ë„¥ì…˜ì— ì…ë‹¨í•˜ê²Œ ëœ ìŠ¤í‹¸í”¼ì— ì€ ì…ë‹¨ ë§ì´ ë²™ê°œì†¡ì„ ì‹œì‘ìœ¼ë¡œ ì´í›„ í™œë°œí•œ í™œë™ì„ í¼ì¹˜ê²Œ ëœë‹¤. ë‹¹ì‹œ í™í•©ì”¬ì—ì„œ í¬ê²Œ íˆíŠ¸í•œ ë§¤ìŠ¬ë¡œì˜ [Young MAstory] ì•¨ë²”ì—ì„œ ê·¸ê°€ ì°¸ì—¬í•œ ê³¡ì€ 3ê³¡ì´ë©° ë‹¹ì‹œ ì…ë‹¨í•œì§€ 1ë…„ ì •ë„ë°–ì— ì•ˆ ì§€ë‚œ ê²ƒì„ ê°ì•ˆí•˜ë©´ ë§ì€ ì‘ì—…ëŸ‰ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´í›„ ê·¸ëŠ” ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ì´ ë””ì§€í„¸ ì‹±ê¸€ [í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]ì˜ íƒ€ì´í‹€ ê³¡ [í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]ì— ì°¸ì—¬í•˜ê²Œ ë˜ì–´ ë”ìš± ë” ê·¸ë¥¼ ì•Œë¦¬ê²Œ ëœë‹¤. 2009ë…„ 3ì›” ì†Œìš¸ì»¤ë„¥ì…˜ì˜ ì²« ì»´í•„ë ˆì´ì…˜ ì•¨ë²” [RapsodY]ê°€ ë°œë§¤ ë˜ì—ˆëŠ”ë° ì´ë•Œ ìŠ¤í‹¸í”¼ì— ì€ íƒ€ì´í‹€ ê³¡ ã€ˆHey maã€‰ë¥¼ í¬í•¨ ë¬´ë ¤ 7ê³¡ì´ë‚˜ ì°¸ì—¬í•˜ì—¬ ë”ìš± ë” ì†Œìš¸ ì»¤ë„¥ì…˜ ë‚´ ê·¸ì˜ ìœ„ì¹˜ë¥¼ ë¦¬ìŠ¤ë„ˆë“¤ì—ê²Œ ê°ì¸ ì‹œì¼°ë‹¤. ì´í›„ ì†Œìš¸ì»¤ë„¥ì…˜ê³¼ Day lifeì˜ ì½œë¼ë³´ ì•¨ë²” [Day life]ì—ì„œ ê·¸ëŠ” ì „ê³¡ì— ì°¸ì—¬í•˜ì—¬ ì™„ì „íˆ ë©”ì¸ ë©¤ë²„ë¡œ ë¶€ìƒí•˜ê²Œ ëœë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " [í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]\n",
      "\n",
      "PRED\n",
      " ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë””ì§€í‹€ì‹±ê¸€ì˜ ì œëª©ì€ í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ì…ë‹ˆë‹¤.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][1], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "í† íŠ¸ë„˜ê³¼ ìœ ë¡œíŒŒë¦¬ê·¸ì—ì„œ ê²½ê¸°í•œ ìƒëŒ€ëŠ” ëˆ„êµ¬ì¸ê°€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2013ë…„ 3ì›” 3ì¼, ë² ì¼ì€ í† íŠ¸ë„˜ì´ 2-1ë¡œ ì´ê¸´ ì•„ìŠ¤ë„ê³¼ì˜ ë¶ëŸ°ë˜ ë”ë¹„ ê²½ê¸°ì—ì„œ ë“ì ì„ ê¸°ë¡í–ˆë‹¤. 3ì›” 7ì¼, í† íŠ¸ë„˜ì€ UEFA ìœ ë¡œíŒŒë¦¬ê·¸ì—ì„œ ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆë¥¼ ìƒëŒ€í–ˆê³ , ë² ì¼ì´ í† íŠ¸ë„˜ì˜ ì„ ì œê³¨ì„ ë„£ëŠ” ê²ƒì„ ì‹œì‘ìœ¼ë¡œ 3-0 ëŒ€ìŠ¹ì„ ê±°ë‘ì—ˆë‹¤. ë² ì¼ì€ 2013ë…„ ì´ˆë°˜ì— ë§¹í™œì•½ì„ ì´ì–´ë‚˜ê°€ 2ì›” í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ ì´ë‹¬ì˜ ì„ ìˆ˜ìƒì„ ë°›ì€ ê²ƒì€ ë¬¼ë¡ , BBCë¡œë¶€í„° ì´ ë‹¬ì˜ ê³¨ 1ì›”ê³¼ 2ì›”ì— ëª¨ë‘ ë“ì ìë¡œë„ ì„ ì •ë˜ì—ˆëŠ”ë°, ê·¸ëŠ” ê°ê° ë…¸ë¦¬ì¹˜ ì‹œí‹°ì „ê³¼ ì›¨ìŠ¤íŠ¸ í–„ ìœ ë‚˜ì´í‹°ë“œì „ì—ì„œì˜ ë“ì ìœ¼ë¡œ ì„ ì •ë˜ì—ˆë‹¤. 4ì›” 4ì¼, ë² ì¼ì€ ë°”ì ¤ê³¼ì˜ UEFA ìœ ë¡œíŒŒë¦¬ê·¸ 8ê°•ì „ì—ì„œ ì˜¤ë¥¸ìª½ ë°œëª© ë¶€ìƒì„ ë‹¹í–ˆë‹¤. ë¶€ìƒì—ì„œ ëŒì•„ì˜¨ ë² ì¼ì€ ë§¨ì²´ìŠ¤í„° ì‹œí‹°ì™€ì˜ í™ˆê²½ê¸°ì—ì„œ ìì‹ ì˜ ë“ì ê³¼ í´ë¦°íŠ¸ ë€í”„ì‹œì˜ ê³¨ì„ ë•ëŠ” ë„ì›€ì„ ê¸°ë¡í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ\n",
      "\n",
      "PRED\n",
      " UEFA ìœ ë¡œíŒŒ ë¦¬ê·¸ì—ì„œ í† íŠ¸ë„˜ê³¼ ê²½ê¸°í•œ ìƒëŒ€ëŠ” ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆê°€ ì•„ë‹ˆì—ˆìœ¼ë©°, ê·¸ ê²½ê¸° ê²°ê³¼ëŠ” 3-0ë¡œ í† íŠ¸ë„˜ì´ ìŠ¹ë¦¬í–ˆë‹¤. ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆëŠ” 8ê°•ì „ì—ì„œ í† íŠ¸ï¿½\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][2], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì—­ì„¸ê¶Œ ê°œë°œì´ ë¯¸ë¤„ì§„ ì´ìœ ëŠ”?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ì´í›„ 2007ë…„ 9ì›” 27ì¼, (ê°€ì¹­)ë¶ì°½ì›ì—­ì„ ë¹„ë¡¯í•œ ìš©ë™ ì¼ì›ì˜ ê·œëª¨ì˜ ë¶ì°½ì›ì—­ ì—­ì„¸ê¶Œ ì¢…í•©ê°œë°œ ì‚¬ì—…ì„ ì¶”ì§„í•  ê²ƒì„ ë°œí‘œí•˜ì—¬ ì´ë‚  ë°•ì™„ìˆ˜ ì°½ì›ì‹œì¥ê³¼ ì‹ í¬ë²” ê²½ìƒë‚¨ë„ê°œë°œê³µì‚¬ ì‚¬ì¥ì´ ìƒí˜¸ ë¶„ë‹´ì„ í†µí•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì§„í•  ê²ƒì„ ê³¨ìë¡œ í•˜ëŠ” ì‹œì •í˜‘ì•½ì„ ì²´ê²°í•˜ì˜€ë‹¤. ì´ ì¢…í•©ê°œë°œ ì‚¬ì—…ì—ëŠ” ê³ ì†ì² ë„ ê°œí†µìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” (ê°€ì¹­)ë¶ì°½ì›ì—­ ì§„ì…ë¡œ ê°œì„  ë¬¸ì œì™€ í•¨ê»˜, ì •ë³‘ì‚°ê³¼ ë¹„ìŒì‚°ì„ ì°¾ëŠ” ì‹œë¯¼ë“¤ì˜ ì£¼ì°¨ê³µê°„ì„ í™•ë³´í•˜ê³  ì—¬ëŸ¬ ìƒì—…, ê³µê³µê¸°ê´€ ë“±ì„ ì£¼ë³€ì— ë°°ì¹˜í•˜ì—¬ ê³µê°„ì²´ê³„ì˜ íš¨ìœ¨ì„± ë“±ì„ ê°œì„  í•  ìˆ˜ ìˆë„ë¡ í•˜ì˜€ë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ” ì—­ì´ ì‹ ì„¤ë˜ëŠ” ìš©ë™ì €ìˆ˜ì§€ ì¼ì› 295,110mì— 1,149ì–µì›ì˜ ì˜ˆì‚°ì„ íˆ¬ì…í•˜ì—¬, ê·¸ ê°€ìš´ë° ì ˆë°˜ì— í•´ë‹¹í•˜ëŠ” 15ë§Œ 2ì²œì—¬mì— ë„ì‹œê¸°ë°˜ì‹œì„¤ì„, 6ë§Œ 1ì²œì—¬mì€ ìƒì—…ìš©ì§€ë¡œ, ë‚˜ë¨¸ì§€ 8ë§Œ 1ì²œì—¬mëŠ” ê¸°íƒ€ì‹œì„¤ìš©ì§€ë¡œ êµ¬ë¶„í•˜ì—¬ ì—­ì„¸ê¶Œê°œë°œì´ ì¶”ì§„ë˜ì—ˆë‹¤. 2007ë…„ ì‹œí–‰í˜‘ì•½ì„ í–ˆë˜ ë‹¹ì‹œì— ì´ ì‚¬ì—…ì€ 2010ë…„ ì´ˆì— ì°©ê³µí•˜ì—¬ 2011ë…„ ë§ ê²½ì— ì™„ê³µ ë  ì˜ˆì •ì´ì—ˆì§€ë§Œ, ê·¸ë¦°ë²¨íŠ¸ í•´ì œì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë©´ì„œ2012ë…„ì— ì°©ê³µí•˜ì—¬ 2014ë…„ì— ì™„ê³µìœ¼ë¡œ ê³„íšì´ ë³€ê²½ë˜ì—ˆê³ , ì‚¬ì—… ì‹œê¸°ë„ 2ë…„ ì´ìƒ ì°¨ì§ˆì„ ë¹šì—ˆë‹¤. ì´ì— ë°•ì™„ìˆ˜ ì°½ì›ì‹œì¥ì€ ì—­ì„¸ê¶Œ ê°œë°œì— ëŒ€í•´ íŠ¹ë³„í•œ ëŒ€ì±…ì„ ê°•êµ¬í•´ì•¼ í•œë‹¤ê³  ë§í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ê·¸ë¦°ë²¨íŠ¸ í•´ì œ\n",
      "\n",
      "PRED\n",
      " ì—­ì„¸ê¶Œ ê°œë°œì´ ë¯¸ë¤„ ì§„ ì´ìœ ëŠ” ë¶ì°½ì›ì—­ surrounding developmentë¥¼ ì¶”ì§„í•˜ê¸° ìœ„í•˜ì—¬ì˜€ìŠµë‹ˆë‹¤.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "untrained.append(\n",
    "    inf_test_one_sample(dataset['test'][3], model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ì•½ 1ë§Œëª…', 'ë¦¬ì˜¹ì˜ ì‹œê°„ë‹¹ ì´ìš©ê° ìˆ˜ëŠ” 10,000ëª…ì…ë‹ˆë‹¤.<|eot_id|>'),\n",
       " ('[í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]', 'ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë””ì§€í‹€ì‹±ê¸€ì˜ ì œëª©ì€ í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ì…ë‹ˆë‹¤.<|eot_id|>'),\n",
       " ('ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ',\n",
       "  'UEFA ìœ ë¡œíŒŒ ë¦¬ê·¸ì—ì„œ í† íŠ¸ë„˜ê³¼ ê²½ê¸°í•œ ìƒëŒ€ëŠ” ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆê°€ ì•„ë‹ˆì—ˆìœ¼ë©°, ê·¸ ê²½ê¸° ê²°ê³¼ëŠ” 3-0ë¡œ í† íŠ¸ë„˜ì´ ìŠ¹ë¦¬í–ˆë‹¤. ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆëŠ” 8ê°•ì „ì—ì„œ í† íŠ¸ï¿½'),\n",
       " ('ê·¸ë¦°ë²¨íŠ¸ í•´ì œ',\n",
       "  'ì—­ì„¸ê¶Œ ê°œë°œì´ ë¯¸ë¤„ ì§„ ì´ìœ ëŠ” ë¶ì°½ì›ì—­ surrounding developmentë¥¼ ì¶”ì§„í•˜ê¸° ìœ„í•˜ì—¬ì˜€ìŠµë‹ˆë‹¤.<|eot_id|>')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(lora_model);\n",
    "FastLanguageModel.for_training(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c806c366b3944108e7acea24fc63e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ef673487a846859776ea9b27f7b4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgyukim/.conda/envs/Llama/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99aa0b59a0d46d6a729865b0096ae80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a3a867e04c499a82e2fdc18f4b4b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Trainer \n",
    "trainer = SFTTrainer(\n",
    "    model = lora_model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 1,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.2,\n",
    "        save_steps=0.2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "í†µì¼ë¯¼ì£¼ë‹¹ì„ ì¥í•™í•˜ê³  ëŒ€í†µë ¹ ì„ ê±° ì¶œë§ˆ ì„ ì–¸ì„ í•œ ì‚¬ëŒì€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "9ì›” 29ì¼ì—ëŠ” ê¹€ì˜ì‚¼ ì´ì¬, ê¹€ëŒ€ì¤‘ ê³ ë¬¸ ê°„ í›„ë³´ë‹¨ì¼í™” íšŒë‹´ì„ í•˜ì˜€ìœ¼ë‚˜ ì´ê²¬ì°¨ì´ë¥¼ ì¢íˆì§€ ëª»í•˜ê³  ê²°ë ¬ë˜ì—ˆë‹¤. 9ì›” 30ì¼ ê¹€ëŒ€ì¤‘ì€ ë‹¤ì‹œ ì œ13ëŒ€ ëŒ€í†µë ¹ ì„ ê±° í›„ë³´ ì¶œë§ˆë¥¼ ê¹€ì˜ì‚¼ê³¼ ì•¼ë‹¹ í›„ë³´ë‹¨ì¼í™” í˜‘ìƒì„ ë²Œì˜€ìœ¼ë‚˜ ì–‘ìê°„ì˜ ì‹œê°ì°¨ì´ë§Œ í™•ì¸í•˜ê³  ê²°ë ¬ë˜ì—ˆë‹¤. ì¬ì•¼ ì¸ì‚¬ë“¤ì˜ í†µí•© ìš”ì²­ì—ë„ ë¶ˆêµ¬í•˜ê³  í˜‘ìƒì´ ê²°ë ¬ë˜ì, ì´ëŠ” êµ°ì‚¬ ì •ê¶Œ í›„ê³„ìë¥¼ ë†“ê³  ì•¼ë‹¹ ì§€ë„ìê°„ ë¶„ì—´í–ˆë‹¤ í•˜ì—¬ ì ì „ ë¶„ì—´ì´ë¼ëŠ” ë¹„íŒì„ ì´ˆë˜í•˜ì˜€ë‹¤. 10ì›” 10ì¼, í†µì¼ë¯¼ì£¼ë‹¹ì„ ì¥ì•…í•œ ê¹€ì˜ì‚¼ì€ ëŒ€í†µë ¹ ì„ ê±° ì¶œë§ˆë¥¼ ë°œí‘œí•˜ê³  ë‚˜ì„œì ë‹¹ë‚´ ê²½ì„ ì—ì„œ ì ˆëŒ€ì ìœ¼ë¡œ ë¶ˆë¦¬í•œ ìœ„ì¹˜ì— ë†“ì—¬ìˆë˜ ê¹€ëŒ€ì¤‘ì€ 10ì›” 18ì¼ í†µì¼ë¯¼ì£¼ë‹¹ì„ íƒˆë‹¹í•˜ì˜€ë‹¤. 11ì›” 12ì¼ì—ëŠ” í‰í™”ë¯¼ì£¼ë‹¹ì„ ì°½ë‹¹í•´ ëŒ€í‘œ ê²¸ 13ëŒ€ ëŒ€í†µë ¹ í›„ë³´ë¡œ ì„ ì¶œëœ ì´í›„ ì•¼ë‹¹ í›„ë³´ì˜€ë˜ ê¹€ì˜ì‚¼ê³¼ í›„ë³´ ë‹¨ì¼í™”ë¥¼ ì´ë£¨ì§€ ëª»í•œ ì±„ 12ì›” 16ì¼ì— ì œ13ëŒ€ ëŒ€í†µë ¹ ì„ ê±°ì— ì¶œë§ˆí–ˆì§€ë§Œ, ë…¸íƒœìš°ì™€ ê¹€ì˜ì‚¼ì—ê²Œ ë°€ë ¤ 611ë§Œ í‘œë¥¼ ì–»ê³  ë‚™ì„ í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ê¹€ì˜ì‚¼<|eot_id|>\n",
      "                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\n",
      "ê¹€ì˜ì‚¼<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(trainer.train_dataset[5][\"input_ids\"]))\n",
    "\n",
    "# trainer.train_datasetì˜ labelsì—ëŠ” instructionì— í•´ë‹¹í•˜ëŠ” ì…ë ¥ë¶€ë¶„ì€ ëª¨ë‘ -100ìœ¼ë¡œ\n",
    "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
    "print(tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 4,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcallingu\u001b[0m (\u001b[33m3d_nerf\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mgyukim/workspaces/courses/LLAMA/wandb/run-20241030_072723-j68h4wds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/3d_nerf/huggingface/runs/j68h4wds' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/3d_nerf/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/3d_nerf/huggingface' target=\"_blank\">https://wandb.ai/3d_nerf/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/3d_nerf/huggingface/runs/j68h4wds' target=\"_blank\">https://wandb.ai/3d_nerf/huggingface/runs/j68h4wds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 08:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.223015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.184050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.167549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.158417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.157640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# í•™ìŠµ ì‹œì‘\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained = []\n",
    "FastLanguageModel.for_inference(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ë¦¬ì˜¹ ì§€í•˜ì² ì˜ ì‹œê°„ ë‹¹ ì´ìš©ê° ìˆ˜ëŠ” ì•½ ëª‡ ëª…ì¸ê°€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ê°€ì¥ ë§ì€ ìŠ¹ê°ì„ ë¹ ë¥´ê²Œ ì´ë™ì‹œí‚¬ ìˆ˜ ìˆëŠ” ìˆ˜ë‹¨ìœ¼ë¡œëŠ” ì§€í•˜ì² ì´ ìˆë‹¤. ë‹¤ë¥¸ êµí†µìˆ˜ë‹¨ê³¼ ë¹„êµí•´ë³¼ë•Œ ì§€í•˜ì² ì˜ ìµœëŒ€ ì¥ì ì€ ë‹¨ìœ„ì‹œê°„ë‹¹ ìˆ˜ì†¡ì¸ì›ì´ ë§ë‹¤ëŠ” ê²ƒì´ë‹¤. 65ëª…ì´ íƒ‘ìŠ¹í•˜ê³  10ë¶„ë§ˆë‹¤ ìš´í–‰í•˜ëŠ” ë²„ìŠ¤ì˜ ì‹œê°„ë‹¹ ìŠ¹ê° ìˆ˜ì†¡ëŸ‰ì€ 390ëª…ì´ë‹¤. 200ëª…ì´ íƒ‘ìŠ¹í•˜ê³  10ë¶„ë§ˆë‹¤ ìš´í–‰í•˜ëŠ” íŠ¸ë¨ì˜ ì‹œê°„ë‹¹ ìŠ¹ê° ìˆ˜ì†¡ëŸ‰ì€ 1200ëª…ì´ë‹¤. 600ëª…ì´ íƒ‘ìŠ¹í•˜ê³ , 2ë¶„ë§ˆë‹¤ ìš´í–‰í•˜ëŠ” ì§€í•˜ì² ì˜ ì‹œê°„ë‹¹ ìŠ¹ê° ìˆ˜ì†¡ëŸ‰ì€ 18,000ëª…ì´ë‹¤. ì´ëŸ¬í•œ ìˆ˜ì†¡ëŸ‰ ë•Œë¬¸ì— ì „ ì„¸ê³„ì ìœ¼ë¡œ ì§€í•˜ì² ì´ ì—†ëŠ” ëŒ€ë„ì‹œëŠ” ì°¾ì•„ë³´ê¸° ì–´ë µë‹¤. í”„ë‘ìŠ¤ ë¦¬ì˜¹ì—ì„œëŠ” ì‹œê°„ë‹¹ ì•½ 1ë§Œëª…ì´ ì§€í•˜ì² ì„ ì´ìš©í•œë‹¤. ì§€í•˜ì² ì˜ ì‹œê°„ë‹¹ ìˆ˜ì†¡ ì¸ì›ì´ ë§ì€ ì´ìœ ëŠ” ì „ìš© ì² ë¡œë¥¼ ì´ìš©í•´ ë‹¤ë‹ˆê¸° ë•Œë¬¸ì´ë‹¤. ìš´í–‰ì— ë°©í•´ê°€ ë ë§Œí•œ ê²ƒì´ ì—†ì–´ í‰ê· ì†ë„ 75kmë¡œ ë‹¬ë¦´ ìˆ˜ ìˆë‹¤. ê·¹ì‹¬í•œ í˜¼ì¡ì´ ë¹šì–´ì§€ëŠ” ì¶œí‡´ê·¼ì‹œê°„ì—ëŠ” 2ë¶„ì— í•œëŒ€ê¼´ë¡œ ìš´í–‰ì´ ë˜ê¸°ë„ í•œë‹¤. í•˜ì§€ë§Œ ì§€í•˜ì²  ì¸í”„ë¼ë¥¼ êµ¬ì¶•í•˜ëŠ”ë° ë§ì€ ì‹œê°„ê³¼ ëˆì´ ë“ ë‹¤. í„°ë„ì„ ëš«ê³  ë ˆì¼ì„ ê¹”ê³ , ì—˜ë¦¬ë² ì´í„°, ê³„ë‹¨, ìŠ¹ê°•ì¥ ë“±ì„ ë§Œë“¤ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì§€í•˜ì² ì€ íŠ¸ë¨ì— ë¹„í•´ 3~5ë°° ê°€ëŸ‰ ë” ë§ì€ ëˆì„ íˆ¬ìí•´ì•¼ í•œë‹¤. ê±´ì„¤ë¹„ëŠ” ì§€ìì²´ì™€ ì¤‘ì•™ì •ë¶€, ê¸°ì—…ë“¤ì˜ ì„¸ê¸ˆ, ê·¸ë¦¬ê³  ìŠ¹ê°ë“¤ì´ ë‚´ëŠ” ìš”ê¸ˆìœ¼ë¡œ ì°¨ì¸° ì¶©ë‹¹ëœë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ì•½ 1ë§Œëª…\n",
      "\n",
      "PRED\n",
      " 1ë§Œëª…<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][0], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë””ì§€í‹€ì‹±ê¸€ ì œëª©ì€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ì†Œìš¸ ì»¤ë„¥ì…˜ì— ì…ë‹¨í•˜ê²Œ ëœ ìŠ¤í‹¸í”¼ì— ì€ ì…ë‹¨ ë§ì´ ë²™ê°œì†¡ì„ ì‹œì‘ìœ¼ë¡œ ì´í›„ í™œë°œí•œ í™œë™ì„ í¼ì¹˜ê²Œ ëœë‹¤. ë‹¹ì‹œ í™í•©ì”¬ì—ì„œ í¬ê²Œ íˆíŠ¸í•œ ë§¤ìŠ¬ë¡œì˜ [Young MAstory] ì•¨ë²”ì—ì„œ ê·¸ê°€ ì°¸ì—¬í•œ ê³¡ì€ 3ê³¡ì´ë©° ë‹¹ì‹œ ì…ë‹¨í•œì§€ 1ë…„ ì •ë„ë°–ì— ì•ˆ ì§€ë‚œ ê²ƒì„ ê°ì•ˆí•˜ë©´ ë§ì€ ì‘ì—…ëŸ‰ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´í›„ ê·¸ëŠ” ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ì´ ë””ì§€í„¸ ì‹±ê¸€ [í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]ì˜ íƒ€ì´í‹€ ê³¡ [í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]ì— ì°¸ì—¬í•˜ê²Œ ë˜ì–´ ë”ìš± ë” ê·¸ë¥¼ ì•Œë¦¬ê²Œ ëœë‹¤. 2009ë…„ 3ì›” ì†Œìš¸ì»¤ë„¥ì…˜ì˜ ì²« ì»´í•„ë ˆì´ì…˜ ì•¨ë²” [RapsodY]ê°€ ë°œë§¤ ë˜ì—ˆëŠ”ë° ì´ë•Œ ìŠ¤í‹¸í”¼ì— ì€ íƒ€ì´í‹€ ê³¡ ã€ˆHey maã€‰ë¥¼ í¬í•¨ ë¬´ë ¤ 7ê³¡ì´ë‚˜ ì°¸ì—¬í•˜ì—¬ ë”ìš± ë” ì†Œìš¸ ì»¤ë„¥ì…˜ ë‚´ ê·¸ì˜ ìœ„ì¹˜ë¥¼ ë¦¬ìŠ¤ë„ˆë“¤ì—ê²Œ ê°ì¸ ì‹œì¼°ë‹¤. ì´í›„ ì†Œìš¸ì»¤ë„¥ì…˜ê³¼ Day lifeì˜ ì½œë¼ë³´ ì•¨ë²” [Day life]ì—ì„œ ê·¸ëŠ” ì „ê³¡ì— ì°¸ì—¬í•˜ì—¬ ì™„ì „íˆ ë©”ì¸ ë©¤ë²„ë¡œ ë¶€ìƒí•˜ê²Œ ëœë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " [í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]\n",
      "\n",
      "PRED\n",
      " í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][1], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "í† íŠ¸ë„˜ê³¼ ìœ ë¡œíŒŒë¦¬ê·¸ì—ì„œ ê²½ê¸°í•œ ìƒëŒ€ëŠ” ëˆ„êµ¬ì¸ê°€?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "2013ë…„ 3ì›” 3ì¼, ë² ì¼ì€ í† íŠ¸ë„˜ì´ 2-1ë¡œ ì´ê¸´ ì•„ìŠ¤ë„ê³¼ì˜ ë¶ëŸ°ë˜ ë”ë¹„ ê²½ê¸°ì—ì„œ ë“ì ì„ ê¸°ë¡í–ˆë‹¤. 3ì›” 7ì¼, í† íŠ¸ë„˜ì€ UEFA ìœ ë¡œíŒŒë¦¬ê·¸ì—ì„œ ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆë¥¼ ìƒëŒ€í–ˆê³ , ë² ì¼ì´ í† íŠ¸ë„˜ì˜ ì„ ì œê³¨ì„ ë„£ëŠ” ê²ƒì„ ì‹œì‘ìœ¼ë¡œ 3-0 ëŒ€ìŠ¹ì„ ê±°ë‘ì—ˆë‹¤. ë² ì¼ì€ 2013ë…„ ì´ˆë°˜ì— ë§¹í™œì•½ì„ ì´ì–´ë‚˜ê°€ 2ì›” í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ ì´ë‹¬ì˜ ì„ ìˆ˜ìƒì„ ë°›ì€ ê²ƒì€ ë¬¼ë¡ , BBCë¡œë¶€í„° ì´ ë‹¬ì˜ ê³¨ 1ì›”ê³¼ 2ì›”ì— ëª¨ë‘ ë“ì ìë¡œë„ ì„ ì •ë˜ì—ˆëŠ”ë°, ê·¸ëŠ” ê°ê° ë…¸ë¦¬ì¹˜ ì‹œí‹°ì „ê³¼ ì›¨ìŠ¤íŠ¸ í–„ ìœ ë‚˜ì´í‹°ë“œì „ì—ì„œì˜ ë“ì ìœ¼ë¡œ ì„ ì •ë˜ì—ˆë‹¤. 4ì›” 4ì¼, ë² ì¼ì€ ë°”ì ¤ê³¼ì˜ UEFA ìœ ë¡œíŒŒë¦¬ê·¸ 8ê°•ì „ì—ì„œ ì˜¤ë¥¸ìª½ ë°œëª© ë¶€ìƒì„ ë‹¹í–ˆë‹¤. ë¶€ìƒì—ì„œ ëŒì•„ì˜¨ ë² ì¼ì€ ë§¨ì²´ìŠ¤í„° ì‹œí‹°ì™€ì˜ í™ˆê²½ê¸°ì—ì„œ ìì‹ ì˜ ë“ì ê³¼ í´ë¦°íŠ¸ ë€í”„ì‹œì˜ ê³¨ì„ ë•ëŠ” ë„ì›€ì„ ê¸°ë¡í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ\n",
      "\n",
      "PRED\n",
      " ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][2], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROMPT\n",
      " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ì—­ì„¸ê¶Œ ê°œë°œì´ ë¯¸ë¤„ì§„ ì´ìœ ëŠ”?\n",
      "\n",
      "Information\n",
      "\n",
      "###\n",
      "ì´í›„ 2007ë…„ 9ì›” 27ì¼, (ê°€ì¹­)ë¶ì°½ì›ì—­ì„ ë¹„ë¡¯í•œ ìš©ë™ ì¼ì›ì˜ ê·œëª¨ì˜ ë¶ì°½ì›ì—­ ì—­ì„¸ê¶Œ ì¢…í•©ê°œë°œ ì‚¬ì—…ì„ ì¶”ì§„í•  ê²ƒì„ ë°œí‘œí•˜ì—¬ ì´ë‚  ë°•ì™„ìˆ˜ ì°½ì›ì‹œì¥ê³¼ ì‹ í¬ë²” ê²½ìƒë‚¨ë„ê°œë°œê³µì‚¬ ì‚¬ì¥ì´ ìƒí˜¸ ë¶„ë‹´ì„ í†µí•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì§„í•  ê²ƒì„ ê³¨ìë¡œ í•˜ëŠ” ì‹œì •í˜‘ì•½ì„ ì²´ê²°í•˜ì˜€ë‹¤. ì´ ì¢…í•©ê°œë°œ ì‚¬ì—…ì—ëŠ” ê³ ì†ì² ë„ ê°œí†µìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” (ê°€ì¹­)ë¶ì°½ì›ì—­ ì§„ì…ë¡œ ê°œì„  ë¬¸ì œì™€ í•¨ê»˜, ì •ë³‘ì‚°ê³¼ ë¹„ìŒì‚°ì„ ì°¾ëŠ” ì‹œë¯¼ë“¤ì˜ ì£¼ì°¨ê³µê°„ì„ í™•ë³´í•˜ê³  ì—¬ëŸ¬ ìƒì—…, ê³µê³µê¸°ê´€ ë“±ì„ ì£¼ë³€ì— ë°°ì¹˜í•˜ì—¬ ê³µê°„ì²´ê³„ì˜ íš¨ìœ¨ì„± ë“±ì„ ê°œì„  í•  ìˆ˜ ìˆë„ë¡ í•˜ì˜€ë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ” ì—­ì´ ì‹ ì„¤ë˜ëŠ” ìš©ë™ì €ìˆ˜ì§€ ì¼ì› 295,110mì— 1,149ì–µì›ì˜ ì˜ˆì‚°ì„ íˆ¬ì…í•˜ì—¬, ê·¸ ê°€ìš´ë° ì ˆë°˜ì— í•´ë‹¹í•˜ëŠ” 15ë§Œ 2ì²œì—¬mì— ë„ì‹œê¸°ë°˜ì‹œì„¤ì„, 6ë§Œ 1ì²œì—¬mì€ ìƒì—…ìš©ì§€ë¡œ, ë‚˜ë¨¸ì§€ 8ë§Œ 1ì²œì—¬mëŠ” ê¸°íƒ€ì‹œì„¤ìš©ì§€ë¡œ êµ¬ë¶„í•˜ì—¬ ì—­ì„¸ê¶Œê°œë°œì´ ì¶”ì§„ë˜ì—ˆë‹¤. 2007ë…„ ì‹œí–‰í˜‘ì•½ì„ í–ˆë˜ ë‹¹ì‹œì— ì´ ì‚¬ì—…ì€ 2010ë…„ ì´ˆì— ì°©ê³µí•˜ì—¬ 2011ë…„ ë§ ê²½ì— ì™„ê³µ ë  ì˜ˆì •ì´ì—ˆì§€ë§Œ, ê·¸ë¦°ë²¨íŠ¸ í•´ì œì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë©´ì„œ2012ë…„ì— ì°©ê³µí•˜ì—¬ 2014ë…„ì— ì™„ê³µìœ¼ë¡œ ê³„íšì´ ë³€ê²½ë˜ì—ˆê³ , ì‚¬ì—… ì‹œê¸°ë„ 2ë…„ ì´ìƒ ì°¨ì§ˆì„ ë¹šì—ˆë‹¤. ì´ì— ë°•ì™„ìˆ˜ ì°½ì›ì‹œì¥ì€ ì—­ì„¸ê¶Œ ê°œë°œì— ëŒ€í•´ íŠ¹ë³„í•œ ëŒ€ì±…ì„ ê°•êµ¬í•´ì•¼ í•œë‹¤ê³  ë§í–ˆë‹¤.\n",
      "###<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANS\n",
      " ê·¸ë¦°ë²¨íŠ¸ í•´ì œ\n",
      "\n",
      "PRED\n",
      " ì—­ì„¸ê¶Œ ì¢…í•©ê°œë°œ<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "trained.append(\n",
    "    inf_test_one_sample(dataset['test'][3], lora_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì •ë‹µ</th>\n",
       "      <th>í•™ìŠµì „ ì¶œë ¥</th>\n",
       "      <th>í•™ìŠµí›„ ì¶œë ¥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì•½ 1ë§Œëª…</td>\n",
       "      <td>ë¦¬ì˜¹ì˜ ì‹œê°„ë‹¹ ì´ìš©ê° ìˆ˜ëŠ” 10,000ëª…ì…ë‹ˆë‹¤.&lt;|eot_id|&gt;</td>\n",
       "      <td>1ë§Œëª…&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]</td>\n",
       "      <td>ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë””ì§€í‹€ì‹±ê¸€ì˜ ì œëª©ì€ í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ì…ë‹ˆë‹¤.&lt;|eot_id|&gt;</td>\n",
       "      <td>í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ</td>\n",
       "      <td>UEFA ìœ ë¡œíŒŒ ë¦¬ê·¸ì—ì„œ í† íŠ¸ë„˜ê³¼ ê²½ê¸°í•œ ìƒëŒ€ëŠ” ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆê°€ ì•„ë‹ˆì—ˆìœ¼ë©°, ê·¸ ...</td>\n",
       "      <td>ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê·¸ë¦°ë²¨íŠ¸ í•´ì œ</td>\n",
       "      <td>ì—­ì„¸ê¶Œ ê°œë°œì´ ë¯¸ë¤„ ì§„ ì´ìœ ëŠ” ë¶ì°½ì›ì—­ surrounding developmentë¥¼...</td>\n",
       "      <td>ì—­ì„¸ê¶Œ ì¢…í•©ê°œë°œ&lt;|eot_id|&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ì •ë‹µ                                             í•™ìŠµì „ ì¶œë ¥  \\\n",
       "0       ì•½ 1ë§Œëª…               ë¦¬ì˜¹ì˜ ì‹œê°„ë‹¹ ì´ìš©ê° ìˆ˜ëŠ” 10,000ëª…ì…ë‹ˆë‹¤.<|eot_id|>   \n",
       "1  [í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤]      ì†Œìš¸ì»¤ë„¥ì…˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë””ì§€í‹€ì‹±ê¸€ì˜ ì œëª©ì€ í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ì…ë‹ˆë‹¤.<|eot_id|>   \n",
       "2    ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ  UEFA ìœ ë¡œíŒŒ ë¦¬ê·¸ì—ì„œ í† íŠ¸ë„˜ê³¼ ê²½ê¸°í•œ ìƒëŒ€ëŠ” ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆê°€ ì•„ë‹ˆì—ˆìœ¼ë©°, ê·¸ ...   \n",
       "3     ê·¸ë¦°ë²¨íŠ¸ í•´ì œ  ì—­ì„¸ê¶Œ ê°œë°œì´ ë¯¸ë¤„ ì§„ ì´ìœ ëŠ” ë¶ì°½ì›ì—­ surrounding developmentë¥¼...   \n",
       "\n",
       "               í•™ìŠµí›„ ì¶œë ¥  \n",
       "0       1ë§Œëª…<|eot_id|>  \n",
       "1  í•´í”¼ í¬ë¦¬ìŠ¤ë§ˆìŠ¤<|eot_id|>  \n",
       "2  ì¸í…Œë¥´ë‚˜ì¹˜ì˜¤ë‚ ë ˆ<|eot_id|>  \n",
       "3  ì—­ì„¸ê¶Œ ì¢…í•©ê°œë°œ<|eot_id|>  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[(utrd[0], utrd[1], trd[1]) for utrd, trd in zip(untrained, trained)],\n",
    "    columns=['ì •ë‹µ', 'í•™ìŠµì „ ì¶œë ¥', 'í•™ìŠµí›„ ì¶œë ¥']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
